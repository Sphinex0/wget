<!DOCTYPE html>
<html class="client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-sticky-header-enabled vector-toc-available" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<title>Hyperparameter optimization - Wikipedia</title>
<script>(function(){var className="client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-sticky-header-enabled vector-toc-available";var cookie=document.cookie.match(/(?:^|; )enwikimwclientpreferences=([^;]+)/);if(cookie){cookie[1].split('%2C').forEach(function(pref){className=className.replace(new RegExp('(^| )'+pref.replace(/-clientpref-\w+$|[^\w-]+/g,'')+'-clientpref-\\w+( |$)'),'$1'+pref+'$2');});}document.documentElement.className=className;}());RLCONF={"wgBreakFrames":false,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"60fed554-9e09-4b71-8e2d-1bb65b0bfa71","wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Hyperparameter_optimization","wgTitle":"Hyperparameter optimization","wgCurRevisionId":1299851399,"wgRevisionId":1299851399,"wgArticleId":54361643,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Articles with short description","Short description is different from Wikidata","Machine learning","Mathematical optimization","Model selection"],"wgPageViewLanguage":"en","wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Hyperparameter_optimization","wgRelevantArticleId":54361643,"wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgRedirectedFrom":"Grid_search","wgNoticeProject":"wikipedia","wgCiteReferencePreviewsActive":false,"wgFlaggedRevsParams":{"tags":{"status":{"levels":1}}},"wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":true,"wgPopupsFlags":0,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":true,"watchlist":true,"tagline":false,"nearby":true},"wgWMESchemaEditAttemptStepOversample":false,"wgWMEPageLength":20000,"wgMetricsPlatformUserExperiments":{"active_experiments":[],"overrides":[],"enrolled":[],"assigned":[],"subject_ids":[],"sampling_units":[]},"wgInternalRedirectTargetUrl":"/wiki/Hyperparameter_optimization#Grid_search","wgEditSubmitButtonLabelPublish":true,"wgULSPosition":"interlanguage","wgULSisCompactLinksEnabled":false,"wgVector2022LanguageInHeader":true,"wgULSisLanguageSelectorEmpty":false,"wgWikibaseItemId":"Q48996162","wgCheckUserClientHintsHeadersJsApi":["brands","architecture","bitness","fullVersionList","mobile","model","platform","platformVersion"],"GEHomepageSuggestedEditsEnableTopics":true,"wgGESuggestedEditsTaskTypes":{"taskTypes":["copyedit","link-recommendation"],"unavailableTaskTypes":[]},"wgGETopicsMatchModeEnabled":false,"wgGELevelingUpEnabledForUser":false};
RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","skins.vector.search.codex.styles":"ready","skins.vector.styles":"ready","skins.vector.icons":"ready","jquery.makeCollapsible.styles":"ready","ext.wikimediamessages.styles":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","wikibase.client.init":"ready"};RLPAGEMODULES=["ext.xLab","mediawiki.action.view.redirect","ext.cite.ux-enhancements","mediawiki.page.media","site","mediawiki.page.ready","jquery.makeCollapsible","mediawiki.toc","skins.vector.js","ext.centralNotice.geoIP","ext.centralNotice.startUp","ext.gadget.ReferenceTooltips","ext.gadget.switcher","ext.urlShortener.toolbar","ext.centralauth.centralautologin","mmv.bootstrap","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.echo.centralauth","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.cx.uls.quick.actions","wikibase.client.vector-2022","ext.checkUser.clientHints","ext.quicksurveys.init","ext.growthExperiments.SuggestedEditSession"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.impl(function(){return["user.options@12s5i",function($,jQuery,require,module){mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
}];});});</script>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediamessages.styles%7Cjquery.makeCollapsible.styles%7Cskins.vector.icons%2Cstyles%7Cskins.vector.search.codex.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector-2022">
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector-2022"></script>
<meta name="ResourceLoaderDynamicStyles" content="">
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector-2022">
<meta name="generator" content="MediaWiki 1.45.0-wmf.12">
<meta name="referrer" content="origin">
<meta name="referrer" content="origin-when-cross-origin">
<meta name="robots" content="max-image-preview:standard">
<meta name="format-detection" content="telephone=no">
<meta name="viewport" content="width=1120">
<meta property="og:title" content="Hyperparameter optimization - Wikipedia">
<meta property="og:type" content="website">
<link rel="preconnect" href="//upload.wikimedia.org">
<link rel="alternate" media="only screen and (max-width: 640px)" href="//en.m.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search">
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit">
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png">
<link rel="icon" href="/static/favicon/wikipedia.ico">
<link rel="search" type="application/opensearchdescription+xml" href="/w/rest.php/v1/search" title="Wikipedia (en)">
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd">
<link rel="canonical" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search">
<link rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">
<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom">
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<link rel="dns-prefetch" href="auth.wikimedia.org">
</head>
<body class="skin--responsive skin-vector skin-vector-search-vue mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Hyperparameter_optimization rootpage-Hyperparameter_optimization skin-vector-2022 action-view"><a class="mw-jump-link" href="#bodyContent">Jump to content</a>
<div class="vector-header-container">
	<header class="vector-header mw-header no-font-mode-scale">
		<div class="vector-header-start">
			<nav class="vector-main-menu-landmark" aria-label="Site">
				
<div id="vector-main-menu-dropdown" class="vector-dropdown vector-main-menu-dropdown vector-button-flush-left vector-button-flush-right"  title="Main menu" >
	<input type="checkbox" id="vector-main-menu-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-main-menu-dropdown" class="vector-dropdown-checkbox "  aria-label="Main menu"  >
	<label id="vector-main-menu-dropdown-label" for="vector-main-menu-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-menu mw-ui-icon-wikimedia-menu"></span>

<span class="vector-dropdown-label-text">Main menu</span>
	</label>
	<div class="vector-dropdown-content">


				<div id="vector-main-menu-unpinned-container" class="vector-unpinned-container">
		
<div id="vector-main-menu" class="vector-main-menu vector-pinnable-element">
	<div
	class="vector-pinnable-header vector-main-menu-pinnable-header vector-pinnable-header-unpinned"
	data-feature-name="main-menu-pinned"
	data-pinnable-element-id="vector-main-menu"
	data-pinned-container-id="vector-main-menu-pinned-container"
	data-unpinned-container-id="vector-main-menu-unpinned-container"
>
	<div class="vector-pinnable-header-label">Main menu</div>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-main-menu.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-main-menu.unpin">hide</button>
</div>

	
<div id="p-navigation" class="vector-menu mw-portlet mw-portlet-navigation"  >
	<div class="vector-menu-heading">
		Navigation
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-mainpage-description" class="mw-list-item"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"><span>Main page</span></a></li><li id="n-contents" class="mw-list-item"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia"><span>Contents</span></a></li><li id="n-currentevents" class="mw-list-item"><a href="/wiki/Portal:Current_events" title="Articles related to current events"><span>Current events</span></a></li><li id="n-randompage" class="mw-list-item"><a href="/wiki/Special:Random" title="Visit a randomly selected article [x]" accesskey="x"><span>Random article</span></a></li><li id="n-aboutsite" class="mw-list-item"><a href="/wiki/Wikipedia:About" title="Learn about Wikipedia and how it works"><span>About Wikipedia</span></a></li><li id="n-contactpage" class="mw-list-item"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia"><span>Contact us</span></a></li>
		</ul>
		
	</div>
</div>

	
	
<div id="p-interaction" class="vector-menu mw-portlet mw-portlet-interaction"  >
	<div class="vector-menu-heading">
		Contribute
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-help" class="mw-list-item"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia"><span>Help</span></a></li><li id="n-introduction" class="mw-list-item"><a href="/wiki/Help:Introduction" title="Learn how to edit Wikipedia"><span>Learn to edit</span></a></li><li id="n-portal" class="mw-list-item"><a href="/wiki/Wikipedia:Community_portal" title="The hub for editors"><span>Community portal</span></a></li><li id="n-recentchanges" class="mw-list-item"><a href="/wiki/Special:RecentChanges" title="A list of recent changes to Wikipedia [r]" accesskey="r"><span>Recent changes</span></a></li><li id="n-upload" class="mw-list-item"><a href="/wiki/Wikipedia:File_upload_wizard" title="Add images or other media for use on Wikipedia"><span>Upload file</span></a></li><li id="n-specialpages" class="mw-list-item"><a href="/wiki/Special:SpecialPages"><span>Special pages</span></a></li>
		</ul>
		
	</div>
</div>

</div>

				</div>

	</div>
</div>

		</nav>
			
<a href="/wiki/Main_Page" class="mw-logo">
	<img class="mw-logo-icon" src="/static/images/icons/wikipedia.png" alt="" aria-hidden="true" height="50" width="50">
	<span class="mw-logo-container skin-invert">
		<img class="mw-logo-wordmark" alt="Wikipedia" src="/static/images/mobile/copyright/wikipedia-wordmark-en.svg" style="width: 7.5em; height: 1.125em;">
		<img class="mw-logo-tagline" alt="The Free Encyclopedia" src="/static/images/mobile/copyright/wikipedia-tagline-en.svg" width="117" height="13" style="width: 7.3125em; height: 0.8125em;">
	</span>
</a>

		</div>
		<div class="vector-header-end">
			
<div id="p-search" role="search" class="vector-search-box-vue  vector-search-box-collapses vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box">
	<a href="/wiki/Special:Search" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only search-toggle" title="Search Wikipedia [f]" accesskey="f"><span class="vector-icon mw-ui-icon-search mw-ui-icon-wikimedia-search"></span>

<span>Search</span>
	</a>
	<div class="vector-typeahead-search-container">
		<div class="cdx-typeahead-search cdx-typeahead-search--show-thumbnail cdx-typeahead-search--auto-expand-width">
			<form action="/w/index.php" id="searchform" class="cdx-search-input cdx-search-input--has-end-button">
				<div id="simpleSearch" class="cdx-search-input__input-wrapper"  data-search-loc="header-moved">
					<div class="cdx-text-input cdx-text-input--has-start-icon">
						<input
							class="cdx-text-input__input mw-searchInput" autocomplete="off"
							 type="search" name="search" placeholder="Search Wikipedia" aria-label="Search Wikipedia" autocapitalize="sentences" spellcheck="false" title="Search Wikipedia [f]" accesskey="f" id="searchInput"
							>
						<span class="cdx-text-input__icon cdx-text-input__start-icon"></span>
					</div>
					<input type="hidden" name="title" value="Special:Search">
				</div>
				<button class="cdx-button cdx-search-input__end-button">Search</button>
			</form>
		</div>
	</div>
</div>

			<nav class="vector-user-links vector-user-links-wide" aria-label="Personal tools">
	<div class="vector-user-links-main">
	
<div id="p-vector-user-menu-preferences" class="vector-menu mw-portlet emptyPortlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

	
<div id="p-vector-user-menu-userpage" class="vector-menu mw-portlet emptyPortlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

	<nav class="vector-appearance-landmark" aria-label="Appearance">
		
<div id="vector-appearance-dropdown" class="vector-dropdown "  title="Change the appearance of the page&#039;s font size, width, and color" >
	<input type="checkbox" id="vector-appearance-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-appearance-dropdown" class="vector-dropdown-checkbox "  aria-label="Appearance"  >
	<label id="vector-appearance-dropdown-label" for="vector-appearance-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-appearance mw-ui-icon-wikimedia-appearance"></span>

<span class="vector-dropdown-label-text">Appearance</span>
	</label>
	<div class="vector-dropdown-content">


			<div id="vector-appearance-unpinned-container" class="vector-unpinned-container">
				
			</div>
		
	</div>
</div>

	</nav>
	
<div id="p-vector-user-menu-notifications" class="vector-menu mw-portlet emptyPortlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

	
<div id="p-vector-user-menu-overflow" class="vector-menu mw-portlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			<li id="pt-sitesupport-2" class="user-links-collapsible-item mw-list-item user-links-collapsible-item"><a data-mw="interface" href="https://donate.wikimedia.org/?wmf_source=donate&amp;wmf_medium=sidebar&amp;wmf_campaign=en.wikipedia.org&amp;uselang=en" class=""><span>Donate</span></a>
</li>
<li id="pt-createaccount-2" class="user-links-collapsible-item mw-list-item user-links-collapsible-item"><a data-mw="interface" href="/w/index.php?title=Special:CreateAccount&amp;returnto=Hyperparameter+optimization" title="You are encouraged to create an account and log in; however, it is not mandatory" class=""><span>Create account</span></a>
</li>
<li id="pt-login-2" class="user-links-collapsible-item mw-list-item user-links-collapsible-item"><a data-mw="interface" href="/w/index.php?title=Special:UserLogin&amp;returnto=Hyperparameter+optimization" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o" class=""><span>Log in</span></a>
</li>

			
		</ul>
		
	</div>
</div>

	</div>
	
<div id="vector-user-links-dropdown" class="vector-dropdown vector-user-menu vector-button-flush-right vector-user-menu-logged-out"  title="Log in and more options" >
	<input type="checkbox" id="vector-user-links-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-user-links-dropdown" class="vector-dropdown-checkbox "  aria-label="Personal tools"  >
	<label id="vector-user-links-dropdown-label" for="vector-user-links-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-ellipsis mw-ui-icon-wikimedia-ellipsis"></span>

<span class="vector-dropdown-label-text">Personal tools</span>
	</label>
	<div class="vector-dropdown-content">


		
<div id="p-personal" class="vector-menu mw-portlet mw-portlet-personal user-links-collapsible-item"  title="User menu" >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="pt-sitesupport" class="user-links-collapsible-item mw-list-item"><a href="https://donate.wikimedia.org/?wmf_source=donate&amp;wmf_medium=sidebar&amp;wmf_campaign=en.wikipedia.org&amp;uselang=en"><span>Donate</span></a></li><li id="pt-createaccount" class="user-links-collapsible-item mw-list-item"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Hyperparameter+optimization" title="You are encouraged to create an account and log in; however, it is not mandatory"><span class="vector-icon mw-ui-icon-userAdd mw-ui-icon-wikimedia-userAdd"></span> <span>Create account</span></a></li><li id="pt-login" class="user-links-collapsible-item mw-list-item"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Hyperparameter+optimization" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o"><span class="vector-icon mw-ui-icon-logIn mw-ui-icon-wikimedia-logIn"></span> <span>Log in</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-user-menu-anon-editor" class="vector-menu mw-portlet mw-portlet-user-menu-anon-editor"  >
	<div class="vector-menu-heading">
		Pages for logged out editors <a href="/wiki/Help:Introduction" aria-label="Learn more about editing"><span>learn more</span></a>
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="pt-anoncontribs" class="mw-list-item"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y"><span>Contributions</span></a></li><li id="pt-anontalk" class="mw-list-item"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n"><span>Talk</span></a></li>
		</ul>
		
	</div>
</div>

	
	</div>
</div>

</nav>

		</div>
	</header>
</div>
<div class="mw-page-container">
	<div class="mw-page-container-inner">
		<div class="vector-sitenotice-container">
			<div id="siteNotice"><!-- CentralNotice --></div>
		</div>
		<div class="vector-column-start">
			<div class="vector-main-menu-container">
		<div id="mw-navigation">
			<nav id="mw-panel" class="vector-main-menu-landmark" aria-label="Site">
				<div id="vector-main-menu-pinned-container" class="vector-pinned-container">
				
				</div>
		</nav>
		</div>
	</div>
	<div class="vector-sticky-pinned-container">
				<nav id="mw-panel-toc" aria-label="Contents" data-event-name="ui.sidebar-toc" class="mw-table-of-contents-container vector-toc-landmark">
					<div id="vector-toc-pinned-container" class="vector-pinned-container">
					<div id="vector-toc" class="vector-toc vector-pinnable-element">
	<div
	class="vector-pinnable-header vector-toc-pinnable-header vector-pinnable-header-pinned"
	data-feature-name="toc-pinned"
	data-pinnable-element-id="vector-toc"
	
	
>
	<h2 class="vector-pinnable-header-label">Contents</h2>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-toc.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-toc.unpin">hide</button>
</div>


	<ul class="vector-toc-contents" id="mw-panel-toc-list">
		<li id="toc-mw-content-text"
			class="vector-toc-list-item vector-toc-level-1">
			<a href="#" class="vector-toc-link">
				<div class="vector-toc-text">(Top)</div>
			</a>
		</li>
		<li id="toc-Approaches"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Approaches">
			<div class="vector-toc-text">
				<span class="vector-toc-numb">1</span>
				<span>Approaches</span>
			</div>
		</a>
		
			<button aria-controls="toc-Approaches-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Approaches subsection</span>
			</button>
		
		<ul id="toc-Approaches-sublist" class="vector-toc-list">
			<li id="toc-Grid_search"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Grid_search">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">1.1</span>
					<span>Grid search</span>
				</div>
			</a>
			
			<ul id="toc-Grid_search-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Random_search"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Random_search">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">1.2</span>
					<span>Random search</span>
				</div>
			</a>
			
			<ul id="toc-Random_search-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Bayesian_optimization"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Bayesian_optimization">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">1.3</span>
					<span>Bayesian optimization</span>
				</div>
			</a>
			
			<ul id="toc-Bayesian_optimization-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Gradient-based_optimization"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Gradient-based_optimization">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">1.4</span>
					<span>Gradient-based optimization</span>
				</div>
			</a>
			
			<ul id="toc-Gradient-based_optimization-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Evolutionary_optimization"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Evolutionary_optimization">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">1.5</span>
					<span>Evolutionary optimization</span>
				</div>
			</a>
			
			<ul id="toc-Evolutionary_optimization-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Population-based"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Population-based">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">1.6</span>
					<span>Population-based</span>
				</div>
			</a>
			
			<ul id="toc-Population-based-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Early_stopping-based"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Early_stopping-based">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">1.7</span>
					<span>Early stopping-based</span>
				</div>
			</a>
			
			<ul id="toc-Early_stopping-based-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Others"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Others">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">1.8</span>
					<span>Others</span>
				</div>
			</a>
			
			<ul id="toc-Others-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Issues_with_hyperparameter_optimization"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Issues_with_hyperparameter_optimization">
			<div class="vector-toc-text">
				<span class="vector-toc-numb">2</span>
				<span>Issues with hyperparameter optimization</span>
			</div>
		</a>
		
		<ul id="toc-Issues_with_hyperparameter_optimization-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-See_also"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#See_also">
			<div class="vector-toc-text">
				<span class="vector-toc-numb">3</span>
				<span>See also</span>
			</div>
		</a>
		
		<ul id="toc-See_also-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-References"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#References">
			<div class="vector-toc-text">
				<span class="vector-toc-numb">4</span>
				<span>References</span>
			</div>
		</a>
		
		<ul id="toc-References-sublist" class="vector-toc-list">
		</ul>
	</li>
</ul>
</div>

					</div>
		</nav>
			</div>
		</div>
		<div class="mw-content-container">
			<main id="content" class="mw-body">
				<header class="mw-body-header vector-page-titlebar no-font-mode-scale">
					<nav aria-label="Contents" class="vector-toc-landmark">
						
<div id="vector-page-titlebar-toc" class="vector-dropdown vector-page-titlebar-toc vector-button-flush-left"  title="Table of Contents" >
	<input type="checkbox" id="vector-page-titlebar-toc-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-page-titlebar-toc" class="vector-dropdown-checkbox "  aria-label="Toggle the table of contents"  >
	<label id="vector-page-titlebar-toc-label" for="vector-page-titlebar-toc-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-listBullet mw-ui-icon-wikimedia-listBullet"></span>

<span class="vector-dropdown-label-text">Toggle the table of contents</span>
	</label>
	<div class="vector-dropdown-content">


							<div id="vector-page-titlebar-toc-unpinned-container" class="vector-unpinned-container">
			</div>
		
	</div>
</div>

					</nav>
					<h1 id="firstHeading" class="firstHeading mw-first-heading"><span class="mw-page-title-main">Hyperparameter optimization</span></h1>
							
<div id="p-lang-btn" class="vector-dropdown mw-portlet mw-portlet-lang"  >
	<input type="checkbox" id="p-lang-btn-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-p-lang-btn" class="vector-dropdown-checkbox mw-interlanguage-selector" aria-label="Go to an article in another language. Available in 10 languages"   >
	<label id="p-lang-btn-label" for="p-lang-btn-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--action-progressive mw-portlet-lang-heading-10" aria-hidden="true"  ><span class="vector-icon mw-ui-icon-language-progressive mw-ui-icon-wikimedia-language-progressive"></span>

<span class="vector-dropdown-label-text">10 languages</span>
	</label>
	<div class="vector-dropdown-content">

		<div class="vector-menu-content">
			
			<ul class="vector-menu-content-list">
				
				<li class="interlanguage-link interwiki-ca mw-list-item"><a href="https://ca.wikipedia.org/wiki/Optimitzaci%C3%B3_d%27hiperpar%C3%A0metres" title="Optimització d&#039;hiperparàmetres – Catalan" lang="ca" hreflang="ca" data-title="Optimització d&#039;hiperparàmetres" data-language-autonym="Català" data-language-local-name="Catalan" class="interlanguage-link-target"><span>Català</span></a></li><li class="interlanguage-link interwiki-de mw-list-item"><a href="https://de.wikipedia.org/wiki/Hyperparameteroptimierung" title="Hyperparameteroptimierung – German" lang="de" hreflang="de" data-title="Hyperparameteroptimierung" data-language-autonym="Deutsch" data-language-local-name="German" class="interlanguage-link-target"><span>Deutsch</span></a></li><li class="interlanguage-link interwiki-es mw-list-item"><a href="https://es.wikipedia.org/wiki/Optimizaci%C3%B3n_de_hiperpar%C3%A1metros" title="Optimización de hiperparámetros – Spanish" lang="es" hreflang="es" data-title="Optimización de hiperparámetros" data-language-autonym="Español" data-language-local-name="Spanish" class="interlanguage-link-target"><span>Español</span></a></li><li class="interlanguage-link interwiki-fa mw-list-item"><a href="https://fa.wikipedia.org/wiki/%D8%A8%D9%87%DB%8C%D9%86%D9%87%E2%80%8C%D8%B3%D8%A7%D8%B2%DB%8C_%D8%A7%D8%A8%D8%B1%D9%BE%D8%A7%D8%B1%D8%A7%D9%85%D8%AA%D8%B1%D9%87%D8%A7" title="بهینه‌سازی ابرپارامترها – Persian" lang="fa" hreflang="fa" data-title="بهینه‌سازی ابرپارامترها" data-language-autonym="فارسی" data-language-local-name="Persian" class="interlanguage-link-target"><span>فارسی</span></a></li><li class="interlanguage-link interwiki-id mw-list-item"><a href="https://id.wikipedia.org/wiki/Optimasi_hiperparameter" title="Optimasi hiperparameter – Indonesian" lang="id" hreflang="id" data-title="Optimasi hiperparameter" data-language-autonym="Bahasa Indonesia" data-language-local-name="Indonesian" class="interlanguage-link-target"><span>Bahasa Indonesia</span></a></li><li class="interlanguage-link interwiki-it mw-list-item"><a href="https://it.wikipedia.org/wiki/Ottimizzazione_degli_iperparametri" title="Ottimizzazione degli iperparametri – Italian" lang="it" hreflang="it" data-title="Ottimizzazione degli iperparametri" data-language-autonym="Italiano" data-language-local-name="Italian" class="interlanguage-link-target"><span>Italiano</span></a></li><li class="interlanguage-link interwiki-ru mw-list-item"><a href="https://ru.wikipedia.org/wiki/%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2" title="Оптимизация гиперпараметров – Russian" lang="ru" hreflang="ru" data-title="Оптимизация гиперпараметров" data-language-autonym="Русский" data-language-local-name="Russian" class="interlanguage-link-target"><span>Русский</span></a></li><li class="interlanguage-link interwiki-sr mw-list-item"><a href="https://sr.wikipedia.org/wiki/%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%98%D0%B0_%D1%85%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D0%B0%D1%80%D0%B0" title="Оптимизација хиперпараметара – Serbian" lang="sr" hreflang="sr" data-title="Оптимизација хиперпараметара" data-language-autonym="Српски / srpski" data-language-local-name="Serbian" class="interlanguage-link-target"><span>Српски / srpski</span></a></li><li class="interlanguage-link interwiki-uk mw-list-item"><a href="https://uk.wikipedia.org/wiki/%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D1%96%D0%B7%D0%B0%D1%86%D1%96%D1%8F_%D0%B3%D1%96%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D1%96%D0%B2" title="Оптимізація гіперпараметрів – Ukrainian" lang="uk" hreflang="uk" data-title="Оптимізація гіперпараметрів" data-language-autonym="Українська" data-language-local-name="Ukrainian" class="interlanguage-link-target"><span>Українська</span></a></li><li class="interlanguage-link interwiki-zh mw-list-item"><a href="https://zh.wikipedia.org/wiki/%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96" title="超参数优化 – Chinese" lang="zh" hreflang="zh" data-title="超参数优化" data-language-autonym="中文" data-language-local-name="Chinese" class="interlanguage-link-target"><span>中文</span></a></li>
			</ul>
			<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q48996162#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>
		</div>

	</div>
</div>
</header>
				<div class="vector-page-toolbar vector-feature-custom-font-size-clientpref--excluded">
					<div class="vector-page-toolbar-container">
						<div id="left-navigation">
							<nav aria-label="Namespaces">
								
<div id="p-associated-pages" class="vector-menu vector-menu-tabs mw-portlet mw-portlet-associated-pages"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-nstab-main" class="selected vector-tab-noicon mw-list-item"><a href="/wiki/Hyperparameter_optimization" title="View the content page [c]" accesskey="c"><span>Article</span></a></li><li id="ca-talk" class="vector-tab-noicon mw-list-item"><a href="/wiki/Talk:Hyperparameter_optimization" rel="discussion" title="Discuss improvements to the content page [t]" accesskey="t"><span>Talk</span></a></li>
		</ul>
		
	</div>
</div>

								
<div id="vector-variants-dropdown" class="vector-dropdown emptyPortlet"  >
	<input type="checkbox" id="vector-variants-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-variants-dropdown" class="vector-dropdown-checkbox " aria-label="Change language variant"   >
	<label id="vector-variants-dropdown-label" for="vector-variants-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet" aria-hidden="true"  ><span class="vector-dropdown-label-text">English</span>
	</label>
	<div class="vector-dropdown-content">


					
<div id="p-variants" class="vector-menu mw-portlet mw-portlet-variants emptyPortlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

				
	</div>
</div>

							</nav>
						</div>
						<div id="right-navigation" class="vector-collapsible">
							<nav aria-label="Views">
								
<div id="p-views" class="vector-menu vector-menu-tabs mw-portlet mw-portlet-views"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-view" class="selected vector-tab-noicon mw-list-item"><a href="/wiki/Hyperparameter_optimization"><span>Read</span></a></li><li id="ca-edit" class="vector-tab-noicon mw-list-item"><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit" title="Edit this page [e]" accesskey="e"><span>Edit</span></a></li><li id="ca-history" class="vector-tab-noicon mw-list-item"><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=history" title="Past revisions of this page [h]" accesskey="h"><span>View history</span></a></li>
		</ul>
		
	</div>
</div>

							</nav>
				
							<nav class="vector-page-tools-landmark" aria-label="Page tools">
								
<div id="vector-page-tools-dropdown" class="vector-dropdown vector-page-tools-dropdown"  >
	<input type="checkbox" id="vector-page-tools-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-page-tools-dropdown" class="vector-dropdown-checkbox "  aria-label="Tools"  >
	<label id="vector-page-tools-dropdown-label" for="vector-page-tools-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet" aria-hidden="true"  ><span class="vector-dropdown-label-text">Tools</span>
	</label>
	<div class="vector-dropdown-content">


									<div id="vector-page-tools-unpinned-container" class="vector-unpinned-container">
						
<div id="vector-page-tools" class="vector-page-tools vector-pinnable-element">
	<div
	class="vector-pinnable-header vector-page-tools-pinnable-header vector-pinnable-header-unpinned"
	data-feature-name="page-tools-pinned"
	data-pinnable-element-id="vector-page-tools"
	data-pinned-container-id="vector-page-tools-pinned-container"
	data-unpinned-container-id="vector-page-tools-unpinned-container"
>
	<div class="vector-pinnable-header-label">Tools</div>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-page-tools.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-page-tools.unpin">hide</button>
</div>

	
<div id="p-cactions" class="vector-menu mw-portlet mw-portlet-cactions emptyPortlet vector-has-collapsible-items"  title="More options" >
	<div class="vector-menu-heading">
		Actions
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-more-view" class="selected vector-more-collapsible-item mw-list-item"><a href="/wiki/Hyperparameter_optimization"><span>Read</span></a></li><li id="ca-more-edit" class="vector-more-collapsible-item mw-list-item"><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit" title="Edit this page [e]" accesskey="e"><span>Edit</span></a></li><li id="ca-more-history" class="vector-more-collapsible-item mw-list-item"><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=history"><span>View history</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-tb" class="vector-menu mw-portlet mw-portlet-tb"  >
	<div class="vector-menu-heading">
		General
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="t-whatlinkshere" class="mw-list-item"><a href="/wiki/Special:WhatLinksHere/Hyperparameter_optimization" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j"><span>What links here</span></a></li><li id="t-recentchangeslinked" class="mw-list-item"><a href="/wiki/Special:RecentChangesLinked/Hyperparameter_optimization" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k"><span>Related changes</span></a></li><li id="t-upload" class="mw-list-item"><a href="//en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u"><span>Upload file</span></a></li><li id="t-permalink" class="mw-list-item"><a href="/w/index.php?title=Hyperparameter_optimization&amp;oldid=1299851399" title="Permanent link to this revision of this page"><span>Permanent link</span></a></li><li id="t-info" class="mw-list-item"><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=info" title="More information about this page"><span>Page information</span></a></li><li id="t-cite" class="mw-list-item"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Hyperparameter_optimization&amp;id=1299851399&amp;wpFormIdentifier=titleform" title="Information on how to cite this page"><span>Cite this page</span></a></li><li id="t-urlshortener" class="mw-list-item"><a href="/w/index.php?title=Special:UrlShortener&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FHyperparameter_optimization%23Grid_search"><span>Get shortened URL</span></a></li><li id="t-urlshortener-qrcode" class="mw-list-item"><a href="/w/index.php?title=Special:QrCode&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FHyperparameter_optimization%23Grid_search"><span>Download QR code</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-coll-print_export" class="vector-menu mw-portlet mw-portlet-coll-print_export"  >
	<div class="vector-menu-heading">
		Print/export
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="coll-download-as-rl" class="mw-list-item"><a href="/w/index.php?title=Special:DownloadAsPdf&amp;page=Hyperparameter_optimization&amp;action=show-download-screen" title="Download this page as a PDF file"><span>Download as PDF</span></a></li><li id="t-print" class="mw-list-item"><a href="/w/index.php?title=Hyperparameter_optimization&amp;printable=yes" title="Printable version of this page [p]" accesskey="p"><span>Printable version</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-wikibase-otherprojects" class="vector-menu mw-portlet mw-portlet-wikibase-otherprojects"  >
	<div class="vector-menu-heading">
		In other projects
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li class="wb-otherproject-link wb-otherproject-commons mw-list-item"><a href="https://commons.wikimedia.org/wiki/Category:Hyperparameter_optimization" hreflang="en"><span>Wikimedia Commons</span></a></li><li id="t-wikibase" class="wb-otherproject-link wb-otherproject-wikibase-dataitem mw-list-item"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q48996162" title="Structured data on this page hosted by Wikidata [g]" accesskey="g"><span>Wikidata item</span></a></li>
		</ul>
		
	</div>
</div>

</div>

									</div>
				
	</div>
</div>

							</nav>
						</div>
					</div>
				</div>
				<div class="vector-column-end no-font-mode-scale">
					<div class="vector-sticky-pinned-container">
						<nav class="vector-page-tools-landmark" aria-label="Page tools">
							<div id="vector-page-tools-pinned-container" class="vector-pinned-container">
				
							</div>
		</nav>
						<nav class="vector-appearance-landmark" aria-label="Appearance">
							<div id="vector-appearance-pinned-container" class="vector-pinned-container">
				<div id="vector-appearance" class="vector-appearance vector-pinnable-element">
	<div
	class="vector-pinnable-header vector-appearance-pinnable-header vector-pinnable-header-pinned"
	data-feature-name="appearance-pinned"
	data-pinnable-element-id="vector-appearance"
	data-pinned-container-id="vector-appearance-pinned-container"
	data-unpinned-container-id="vector-appearance-unpinned-container"
>
	<div class="vector-pinnable-header-label">Appearance</div>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-appearance.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-appearance.unpin">hide</button>
</div>


</div>

							</div>
		</nav>
					</div>
				</div>
				<div id="bodyContent" class="vector-body" aria-labelledby="firstHeading" data-mw-ve-target-container>
					<div class="vector-body-before-content">
							<div class="mw-indicators">
		</div>

						<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
					</div>
					<div id="contentSub"><div id="mw-content-subtitle"><span class="mw-redirectedfrom">(Redirected from <a href="/w/index.php?title=Grid_search&amp;redirect=no" class="mw-redirect" title="Grid search">Grid search</a>)</span></div></div>
					
					
					<div id="mw-content-text" class="mw-body-content"><div class="mw-content-ltr mw-parser-output" lang="en" dir="ltr"><div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">The process of finding the optimal set of variables 
for a machine learning algorithm</div>
<p>In <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a>, <b>hyperparameter optimization</b><sup id="cite_ref-1" class="reference"><a href="#cite_note-1"><span class="cite-bracket">[</span>1<span class="cite-bracket">]</span></a></sup> or tuning is the problem of choosing a set of optimal <a href="/wiki/Hyperparameter_(machine_learning)" title="Hyperparameter (machine learning)">hyperparameters</a> for a learning algorithm. A hyperparameter is a <a href="/wiki/Parameter" title="Parameter">parameter</a> whose value is used to control the learning process, which must be configured before the process starts.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2"><span class="cite-bracket">[</span>2<span class="cite-bracket">]</span></a></sup><sup id="cite_ref-3" class="reference"><a href="#cite_note-3"><span class="cite-bracket">[</span>3<span class="cite-bracket">]</span></a></sup>
</p><p>Hyperparameter optimization determines the set of hyperparameters that yields an optimal model which minimizes a predefined <a href="/wiki/Loss_function" title="Loss function">loss function</a> on a given <a href="/wiki/Data_set" title="Data set">data set</a>.<sup id="cite_ref-abs1502.02127_4-0" class="reference"><a href="#cite_note-abs1502.02127-4"><span class="cite-bracket">[</span>4<span class="cite-bracket">]</span></a></sup>  The objective function takes a set of hyperparameters and returns the associated loss.<sup id="cite_ref-abs1502.02127_4-1" class="reference"><a href="#cite_note-abs1502.02127-4"><span class="cite-bracket">[</span>4<span class="cite-bracket">]</span></a></sup> <a href="/wiki/Cross-validation_(statistics)" title="Cross-validation (statistics)">Cross-validation</a> is often used to estimate this generalization performance, and therefore choose the set of values for hyperparameters that maximize it.<sup id="cite_ref-bergstra_5-0" class="reference"><a href="#cite_note-bergstra-5"><span class="cite-bracket">[</span>5<span class="cite-bracket">]</span></a></sup>
</p>
<meta property="mw:PageProp/toc">
<div class="mw-heading mw-heading2"><h2 id="Approaches">Approaches</h2><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit&amp;section=1" title="Edit section: Approaches"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="/wiki/File:Hyperparameter_Optimization_using_Grid_Search.svg" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Hyperparameter_Optimization_using_Grid_Search.svg/250px-Hyperparameter_Optimization_using_Grid_Search.svg.png" decoding="async" width="250" height="167" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Hyperparameter_Optimization_using_Grid_Search.svg/500px-Hyperparameter_Optimization_using_Grid_Search.svg.png 1.5x" data-file-width="540" data-file-height="360"></a><figcaption>Grid search across different values of two hyperparameters. For each hyperparameter, 10 different values are considered, so a total of 100 different combinations are evaluated and compared. Blue contours indicate regions with strong results, whereas red ones show regions with poor results.</figcaption></figure>
<div class="mw-heading mw-heading3"><h3 id="Grid_search">Grid search</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit&amp;section=2" title="Edit section: Grid search"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>The traditional method for hyperparameter optimization has been <i>grid search</i>, or a <i>parameter sweep</i>, which is simply an <a href="/wiki/Brute-force_search" title="Brute-force search">exhaustive searching</a> through a manually specified subset of the hyperparameter space of a learning algorithm. A grid search algorithm must be guided by some performance metric, typically measured by <a href="/wiki/Cross-validation_(statistics)" title="Cross-validation (statistics)">cross-validation</a> on the training set<sup id="cite_ref-6" class="reference"><a href="#cite_note-6"><span class="cite-bracket">[</span>6<span class="cite-bracket">]</span></a></sup>
or evaluation on a hold-out validation set.<sup id="cite_ref-7" class="reference"><a href="#cite_note-7"><span class="cite-bracket">[</span>7<span class="cite-bracket">]</span></a></sup>
</p><p>Since the parameter space of a machine learner may include real-valued or unbounded value spaces for certain parameters, manually set bounds and discretization may be necessary before applying grid search.
</p><p>For example, a typical soft-margin <a href="/wiki/Support_vector_machine" title="Support vector machine">SVM</a> <a href="/wiki/Statistical_classification" title="Statistical classification">classifier</a> equipped with an <a href="/wiki/Radial_basis_function_kernel" title="Radial basis function kernel">RBF kernel</a> has at least two hyperparameters that need to be tuned for good performance on unseen data: a regularization constant <i>C</i> and a kernel hyperparameter γ. Both parameters are continuous, so to perform grid search, one selects a finite set of "reasonable" values for each, say
</p>
<dl><dd><span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C\in \{10,100,1000\}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
        <mo>∈<!-- ∈ --></mo>
        <mo fence="false" stretchy="false">{</mo>
        <mn>10</mn>
        <mo>,</mo>
        <mn>100</mn>
        <mo>,</mo>
        <mn>1000</mn>
        <mo fence="false" stretchy="false">}</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C\in \{10,100,1000\}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4124e15320f26a727f12f02d9bc61edc512878fd" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:19.462ex; height:2.843ex;" alt="{\displaystyle C\in \{10,100,1000\}}"></span></dd>
<dd><span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle \gamma \in \{0.1,0.2,0.5,1.0\}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>γ<!-- γ --></mi>
        <mo>∈<!-- ∈ --></mo>
        <mo fence="false" stretchy="false">{</mo>
        <mn>0.1</mn>
        <mo>,</mo>
        <mn>0.2</mn>
        <mo>,</mo>
        <mn>0.5</mn>
        <mo>,</mo>
        <mn>1.0</mn>
        <mo fence="false" stretchy="false">}</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \gamma \in \{0.1,0.2,0.5,1.0\}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/add7d5ca68cbe82cefb41c6299f04106c03e120f" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:21.417ex; height:2.843ex;" alt="{\displaystyle \gamma \in \{0.1,0.2,0.5,1.0\}}"></span></dd></dl>
<p>Grid search then trains an SVM with each pair (<i>C</i>, γ) in the <a href="/wiki/Cartesian_product" title="Cartesian product">Cartesian product</a> of these two sets and evaluates their performance on a held-out validation set (or by internal cross-validation on the training set, in which case multiple SVMs are trained per pair). Finally, the grid search algorithm outputs the settings that achieved the highest score in the validation procedure.
</p><p>Grid search suffers from the <a href="/wiki/Curse_of_dimensionality" title="Curse of dimensionality">curse of dimensionality</a>, but is often <a href="/wiki/Embarrassingly_parallel" title="Embarrassingly parallel">embarrassingly parallel</a> because the hyperparameter settings it evaluates are typically independent of each other.<sup id="cite_ref-bergstra_5-1" class="reference"><a href="#cite_note-bergstra-5"><span class="cite-bracket">[</span>5<span class="cite-bracket">]</span></a></sup>
</p>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="/wiki/File:Hyperparameter_Optimization_using_Random_Search.svg" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/7/74/Hyperparameter_Optimization_using_Random_Search.svg/250px-Hyperparameter_Optimization_using_Random_Search.svg.png" decoding="async" width="250" height="167" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/7/74/Hyperparameter_Optimization_using_Random_Search.svg/500px-Hyperparameter_Optimization_using_Random_Search.svg.png 1.5x" data-file-width="540" data-file-height="360"></a><figcaption>Random search across different combinations of values for two hyperparameters. In this example, 100 different random choices are evaluated. The green bars show that more individual values for each hyperparameter are considered compared to a grid search.</figcaption></figure>
<div class="mw-heading mw-heading3"><h3 id="Random_search">Random search</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit&amp;section=3" title="Edit section: Random search"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>Random Search replaces the exhaustive enumeration of all combinations by selecting them randomly. This can be simply applied to the discrete setting described above, but also generalizes to continuous and mixed spaces. A benefit over grid search is that random search can explore many more values than grid search could for continuous hyperparameters. It can outperform Grid search, especially when only a small number of hyperparameters affects the final performance of the machine learning algorithm.<sup id="cite_ref-bergstra_5-2" class="reference"><a href="#cite_note-bergstra-5"><span class="cite-bracket">[</span>5<span class="cite-bracket">]</span></a></sup> In this case, the optimization problem is said to have a low intrinsic dimensionality.<sup id="cite_ref-8" class="reference"><a href="#cite_note-8"><span class="cite-bracket">[</span>8<span class="cite-bracket">]</span></a></sup> Random Search is also <a href="/wiki/Embarrassingly_parallel" title="Embarrassingly parallel">embarrassingly parallel</a>, and additionally allows the inclusion of prior knowledge by specifying the distribution from which to sample. Despite its simplicity, random search remains one of the important base-lines against which to compare the performance of new hyperparameter optimization methods.
</p>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="/wiki/File:Hyperparameter_Optimization_using_Tree-Structured_Parzen_Estimators.svg" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Hyperparameter_Optimization_using_Tree-Structured_Parzen_Estimators.svg/250px-Hyperparameter_Optimization_using_Tree-Structured_Parzen_Estimators.svg.png" decoding="async" width="250" height="167" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Hyperparameter_Optimization_using_Tree-Structured_Parzen_Estimators.svg/500px-Hyperparameter_Optimization_using_Tree-Structured_Parzen_Estimators.svg.png 1.5x" data-file-width="540" data-file-height="360"></a><figcaption>Methods such as Bayesian optimization smartly explore the space of potential choices of hyperparameters by deciding which combination to explore next based on previous observations.</figcaption></figure>
<div class="mw-heading mw-heading3"><h3 id="Bayesian_optimization">Bayesian optimization</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit&amp;section=4" title="Edit section: Bayesian optimization"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<style data-mw-deduplicate="TemplateStyles:r1236090951">.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}</style><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Bayesian_optimization" title="Bayesian optimization">Bayesian optimization</a></div>
<p>Bayesian optimization is a global optimization method for noisy black-box functions.  Applied to hyperparameter optimization, Bayesian optimization builds a probabilistic model of the function mapping from hyperparameter values to the objective evaluated on a validation set. By iteratively evaluating a promising hyperparameter configuration based on the current model, and then updating it, Bayesian optimization aims to gather observations revealing as much information as possible about this function and, in particular, the location of the optimum. It tries to balance exploration (hyperparameters for which the outcome is most uncertain) and exploitation (hyperparameters expected close to the optimum). In practice, Bayesian optimization has been shown<sup id="cite_ref-hutter_9-0" class="reference"><a href="#cite_note-hutter-9"><span class="cite-bracket">[</span>9<span class="cite-bracket">]</span></a></sup><sup id="cite_ref-bergstra11_10-0" class="reference"><a href="#cite_note-bergstra11-10"><span class="cite-bracket">[</span>10<span class="cite-bracket">]</span></a></sup><sup id="cite_ref-snoek_11-0" class="reference"><a href="#cite_note-snoek-11"><span class="cite-bracket">[</span>11<span class="cite-bracket">]</span></a></sup><sup id="cite_ref-thornton_12-0" class="reference"><a href="#cite_note-thornton-12"><span class="cite-bracket">[</span>12<span class="cite-bracket">]</span></a></sup><sup id="cite_ref-krnc_13-0" class="reference"><a href="#cite_note-krnc-13"><span class="cite-bracket">[</span>13<span class="cite-bracket">]</span></a></sup> to obtain better results in fewer evaluations compared to grid search and random search, due to the ability to reason about the quality of experiments before they are run.
</p>
<div class="mw-heading mw-heading3"><h3 id="Gradient-based_optimization">Gradient-based optimization</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit&amp;section=5" title="Edit section: Gradient-based optimization"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>For specific learning algorithms, it is possible to compute the gradient with respect to hyperparameters and then optimize the hyperparameters using <a href="/wiki/Gradient_descent" title="Gradient descent">gradient descent</a>. The first usage of these techniques was focused on neural networks.<sup id="cite_ref-14" class="reference"><a href="#cite_note-14"><span class="cite-bracket">[</span>14<span class="cite-bracket">]</span></a></sup> Since then, these methods have been extended to other models such as <a href="/wiki/Support_vector_machine" title="Support vector machine">support vector machines</a><sup id="cite_ref-15" class="reference"><a href="#cite_note-15"><span class="cite-bracket">[</span>15<span class="cite-bracket">]</span></a></sup> or logistic regression.<sup id="cite_ref-16" class="reference"><a href="#cite_note-16"><span class="cite-bracket">[</span>16<span class="cite-bracket">]</span></a></sup>
</p><p>A different approach in order to obtain a gradient with respect to hyperparameters consists in differentiating the steps of an iterative optimization algorithm using  <a href="/wiki/Automatic_differentiation" title="Automatic differentiation">automatic differentiation</a>.<sup id="cite_ref-17" class="reference"><a href="#cite_note-17"><span class="cite-bracket">[</span>17<span class="cite-bracket">]</span></a></sup><sup id="cite_ref-abs1502.03492_18-0" class="reference"><a href="#cite_note-abs1502.03492-18"><span class="cite-bracket">[</span>18<span class="cite-bracket">]</span></a></sup><sup id="cite_ref-19" class="reference"><a href="#cite_note-19"><span class="cite-bracket">[</span>19<span class="cite-bracket">]</span></a></sup><sup id="cite_ref-20" class="reference"><a href="#cite_note-20"><span class="cite-bracket">[</span>20<span class="cite-bracket">]</span></a></sup> A more recent work along this direction uses the <a href="/wiki/Implicit_function_theorem" title="Implicit function theorem">implicit function theorem</a> to calculate hypergradients and proposes a stable approximation of the inverse Hessian. The method scales to millions of hyperparameters and requires constant memory.<sup id="cite_ref-21" class="reference"><a href="#cite_note-21"><span class="cite-bracket">[</span>21<span class="cite-bracket">]</span></a></sup>
</p><p>In a different approach,<sup id="cite_ref-22" class="reference"><a href="#cite_note-22"><span class="cite-bracket">[</span>22<span class="cite-bracket">]</span></a></sup> a hypernetwork is trained to approximate the best response function. One of the advantages of this method is that it can handle discrete hyperparameters as well. Self-tuning networks<sup id="cite_ref-23" class="reference"><a href="#cite_note-23"><span class="cite-bracket">[</span>23<span class="cite-bracket">]</span></a></sup> offer a memory efficient version of this approach by choosing a compact representation for the hypernetwork. More recently, Δ-STN<sup id="cite_ref-24" class="reference"><a href="#cite_note-24"><span class="cite-bracket">[</span>24<span class="cite-bracket">]</span></a></sup> has improved this method further by a slight reparameterization of the hypernetwork which speeds up training. Δ-STN also yields a better approximation of the best-response Jacobian by linearizing the network in the weights, hence removing unnecessary nonlinear effects of large changes in the weights.
</p><p>Apart from hypernetwork approaches, gradient-based methods can be used to optimize discrete hyperparameters also by adopting a continuous relaxation of the parameters.<sup id="cite_ref-25" class="reference"><a href="#cite_note-25"><span class="cite-bracket">[</span>25<span class="cite-bracket">]</span></a></sup> Such methods have been extensively used for the optimization of architecture hyperparameters in <a href="/wiki/Neural_architecture_search" title="Neural architecture search">neural architecture search</a>.
</p>
<div class="mw-heading mw-heading3"><h3 id="Evolutionary_optimization">Evolutionary optimization</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit&amp;section=6" title="Edit section: Evolutionary optimization"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1236090951"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Evolutionary_algorithm" title="Evolutionary algorithm">Evolutionary algorithm</a></div>
<p>Evolutionary optimization is a methodology for the global optimization of noisy black-box functions. In hyperparameter optimization, evolutionary optimization uses <a href="/wiki/Evolutionary_algorithms" class="mw-redirect" title="Evolutionary algorithms">evolutionary algorithms</a> to search the space of hyperparameters for a given algorithm.<sup id="cite_ref-bergstra11_10-1" class="reference"><a href="#cite_note-bergstra11-10"><span class="cite-bracket">[</span>10<span class="cite-bracket">]</span></a></sup> Evolutionary hyperparameter optimization follows a <a href="/wiki/Evolutionary_algorithm#Implementation" title="Evolutionary algorithm">process</a> inspired by the biological concept of <a href="/wiki/Evolution" title="Evolution">evolution</a>:
</p>
<ol><li>Create an initial population of random solutions (i.e., randomly generate tuples of hyperparameters, typically 100+)</li>
<li>Evaluate the hyperparameter tuples and acquire their <a href="/wiki/Fitness_function" title="Fitness function">fitness function</a> (e.g., 10-fold <a href="/wiki/Cross-validation_(statistics)" title="Cross-validation (statistics)">cross-validation</a> accuracy of the machine learning algorithm with those hyperparameters)</li>
<li>Rank the hyperparameter tuples by their relative fitness</li>
<li>Replace the worst-performing hyperparameter tuples with new ones generated via <a href="/wiki/Crossover_(genetic_algorithm)" class="mw-redirect" title="Crossover (genetic algorithm)">crossover</a> and <a href="/wiki/Mutation_(genetic_algorithm)" class="mw-redirect" title="Mutation (genetic algorithm)">mutation</a></li>
<li>Repeat steps 2-4 until satisfactory algorithm performance is reached or is no longer improving.</li></ol>
<p>Evolutionary optimization has been used in hyperparameter optimization for statistical machine learning algorithms,<sup id="cite_ref-bergstra11_10-2" class="reference"><a href="#cite_note-bergstra11-10"><span class="cite-bracket">[</span>10<span class="cite-bracket">]</span></a></sup> <a href="/wiki/Automated_machine_learning" title="Automated machine learning">automated machine learning</a>, typical neural network <sup id="cite_ref-kousiouris1_26-0" class="reference"><a href="#cite_note-kousiouris1-26"><span class="cite-bracket">[</span>26<span class="cite-bracket">]</span></a></sup> and <a href="/wiki/Deep_learning#Deep_neural_networks" title="Deep learning">deep neural network</a> architecture search,<sup id="cite_ref-miikkulainen1_27-0" class="reference"><a href="#cite_note-miikkulainen1-27"><span class="cite-bracket">[</span>27<span class="cite-bracket">]</span></a></sup><sup id="cite_ref-jaderberg1_28-0" class="reference"><a href="#cite_note-jaderberg1-28"><span class="cite-bracket">[</span>28<span class="cite-bracket">]</span></a></sup> as well as training of the weights in deep neural networks.<sup id="cite_ref-such1_29-0" class="reference"><a href="#cite_note-such1-29"><span class="cite-bracket">[</span>29<span class="cite-bracket">]</span></a></sup>
</p>
<div class="mw-heading mw-heading3"><h3 id="Population-based">Population-based</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit&amp;section=7" title="Edit section: Population-based"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>Population Based Training (PBT) learns both hyperparameter values and network weights. Multiple learning processes operate independently, using different hyperparameters. As with evolutionary methods, poorly performing models are iteratively replaced with models that adopt modified hyperparameter values and weights based on the better performers. This replacement model warm starting is the primary differentiator between PBT and other evolutionary methods. PBT thus allows the hyperparameters to evolve and eliminates the need for manual hypertuning. The process makes no assumptions regarding model architecture, loss functions or training procedures.
</p><p>PBT and its variants are adaptive methods: they update hyperparameters during the training of the models. On the contrary, non-adaptive methods have the sub-optimal strategy to assign a constant set of hyperparameters for the whole training.<sup id="cite_ref-30" class="reference"><a href="#cite_note-30"><span class="cite-bracket">[</span>30<span class="cite-bracket">]</span></a></sup>
</p>
<div class="mw-heading mw-heading3"><h3 id="Early_stopping-based">Early stopping-based</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit&amp;section=8" title="Edit section: Early stopping-based"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="/wiki/File:Successive-halving-for-eight-arbitrary-hyperparameter-configurations.png" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Successive-halving-for-eight-arbitrary-hyperparameter-configurations.png/250px-Successive-halving-for-eight-arbitrary-hyperparameter-configurations.png" decoding="async" width="250" height="146" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Successive-halving-for-eight-arbitrary-hyperparameter-configurations.png/375px-Successive-halving-for-eight-arbitrary-hyperparameter-configurations.png 1.5x, //upload.wikimedia.org/wikipedia/commons/8/8e/Successive-halving-for-eight-arbitrary-hyperparameter-configurations.png 2x" data-file-width="469" data-file-height="274"></a><figcaption>Successive halving for eight arbitrary hyperparameter configurations. The approach starts with eight models with different configurations and consecutively applies successive halving until only one model remains.</figcaption></figure>
<p>A class of early stopping-based hyperparameter optimization algorithms is purpose built for large search spaces of continuous and discrete hyperparameters, particularly when the computational cost to evaluate the performance of a set of hyperparameters is high. Irace implements the iterated racing algorithm, that focuses the search around the most promising configurations, using statistical tests to discard the ones that perform poorly.<sup id="cite_ref-irace_31-0" class="reference"><a href="#cite_note-irace-31"><span class="cite-bracket">[</span>31<span class="cite-bracket">]</span></a></sup><sup id="cite_ref-race_32-0" class="reference"><a href="#cite_note-race-32"><span class="cite-bracket">[</span>32<span class="cite-bracket">]</span></a></sup>
Another early stopping hyperparameter optimization algorithm is successive halving (SHA),<sup id="cite_ref-33" class="reference"><a href="#cite_note-33"><span class="cite-bracket">[</span>33<span class="cite-bracket">]</span></a></sup> which begins as a random search but periodically prunes low-performing models, thereby focusing computational resources on more promising models.  Asynchronous successive halving (ASHA)<sup id="cite_ref-34" class="reference"><a href="#cite_note-34"><span class="cite-bracket">[</span>34<span class="cite-bracket">]</span></a></sup> further improves upon SHA's resource utilization profile by removing the need to synchronously evaluate and prune low-performing models. Hyperband<sup id="cite_ref-35" class="reference"><a href="#cite_note-35"><span class="cite-bracket">[</span>35<span class="cite-bracket">]</span></a></sup> is a higher level early stopping-based algorithm that invokes SHA or ASHA multiple times with varying levels of pruning aggressiveness, in order to be more widely applicable and with fewer required inputs.
</p>
<div class="mw-heading mw-heading3"><h3 id="Others">Others</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit&amp;section=9" title="Edit section: Others"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p><a href="/wiki/Radial_basis_function" title="Radial basis function">RBF</a><sup id="cite_ref-abs1705.08520_36-0" class="reference"><a href="#cite_note-abs1705.08520-36"><span class="cite-bracket">[</span>36<span class="cite-bracket">]</span></a></sup> and <a href="/wiki/Spectral_method" title="Spectral method">spectral</a><sup id="cite_ref-abs1706.00764_37-0" class="reference"><a href="#cite_note-abs1706.00764-37"><span class="cite-bracket">[</span>37<span class="cite-bracket">]</span></a></sup> approaches have also been developed.
</p>
<div class="mw-heading mw-heading2"><h2 id="Issues_with_hyperparameter_optimization">Issues with hyperparameter optimization</h2><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit&amp;section=10" title="Edit section: Issues with hyperparameter optimization"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>When hyperparameter optimization is done, the set of hyperparameters are often fitted on a training set and selected based on the generalization performance, or score, of a validation set. However, this procedure is at risk of overfitting the hyperparameters to the validation set. Therefore, the generalization performance score of the validation set (which can be several sets in the case of a cross-validation procedure) cannot be used to simultaneously estimate the generalization performance of the final model. In order to do so, the generalization performance has to be evaluated on a set independent (which has no intersection) of the set (or sets) used for the optimization of the hyperparameters, otherwise the performance might give a value which is too optimistic (too large). This can be done on a second test set, or through an outer <a href="/wiki/Cross-validation_(statistics)" title="Cross-validation (statistics)">cross-validation</a> procedure called nested cross-validation, which allows an unbiased estimation of the generalization performance of the model, taking into account the bias due to the hyperparameter optimization.
</p>
<div class="mw-heading mw-heading2"><h2 id="See_also">See also</h2><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit&amp;section=11" title="Edit section: See also"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<ul><li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">Automated machine learning</a></li>
<li><a href="/wiki/Neural_architecture_search" title="Neural architecture search">Neural architecture search</a></li>
<li><a href="/wiki/Meta-optimization" title="Meta-optimization">Meta-optimization</a></li>
<li><a href="/wiki/Model_selection" title="Model selection">Model selection</a></li>
<li><a href="/wiki/Self-tuning" title="Self-tuning">Self-tuning</a></li>
<li><a href="/wiki/XGBoost" title="XGBoost">XGBoost</a></li>
<li><a href="/wiki/Optuna" title="Optuna">Optuna</a></li></ul>
<div class="mw-heading mw-heading2"><h2 id="References">References</h2><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hyperparameter_optimization&amp;action=edit&amp;section=12" title="Edit section: References"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<style data-mw-deduplicate="TemplateStyles:r1239543626">.mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style><div class="reflist reflist-columns references-column-width" style="column-width: 30em;">
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text">Matthias Feurer and Frank Hutter. <a rel="nofollow" class="external text" href="https://link.springer.com/content/pdf/10.1007%2F978-3-030-05318-5_1.pdf">Hyperparameter optimization</a>. In: <i>AutoML: Methods, Systems, Challenges</i>, pages 3–38.</span>
</li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><style data-mw-deduplicate="TemplateStyles:r1238218222">.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}</style><cite id="CITEREFYang2020" class="citation journal cs1">Yang, Li (2020). "On hyperparameter optimization of machine learning algorithms: Theory and practice". <i>Neurocomputing</i>. <b>415</b>: <span class="nowrap">295–</span>316. <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2007.15745">2007.15745</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.neucom.2020.07.061">10.1016/j.neucom.2020.07.061</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neurocomputing&amp;rft.atitle=On+hyperparameter+optimization+of+machine+learning+algorithms%3A+Theory+and+practice&amp;rft.volume=415&amp;rft.pages=295-316&amp;rft.date=2020&amp;rft_id=info%3Aarxiv%2F2007.15745&amp;rft_id=info%3Adoi%2F10.1016%2Fj.neucom.2020.07.061&amp;rft.aulast=Yang&amp;rft.aufirst=Li&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFFranceschiDoniniPerroneKlein2024" class="citation arxiv cs1">Franceschi L, Donini M, Perrone V, Klein A, Archambeau C, Seeger M, Pontil M, Frasconi P (2024). "Hyperparameter Optimization in Machine Learning". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2410.22854">2410.22854</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/stat.ML">stat.ML</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Hyperparameter+Optimization+in+Machine+Learning&amp;rft.date=2024&amp;rft_id=info%3Aarxiv%2F2410.22854&amp;rft.aulast=Franceschi&amp;rft.aufirst=L&amp;rft.au=Donini%2C+M&amp;rft.au=Perrone%2C+V&amp;rft.au=Klein%2C+A&amp;rft.au=Archambeau%2C+C&amp;rft.au=Seeger%2C+M&amp;rft.au=Pontil%2C+M&amp;rft.au=Frasconi%2C+P&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-abs1502.02127-4"><span class="mw-cite-backlink">^ <a href="#cite_ref-abs1502.02127_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-abs1502.02127_4-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFClaesenBart_De_Moor2015" class="citation arxiv cs1">Claesen, Marc; Bart De Moor (2015). "Hyperparameter Search in Machine Learning". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1502.02127">1502.02127</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Hyperparameter+Search+in+Machine+Learning&amp;rft.date=2015&amp;rft_id=info%3Aarxiv%2F1502.02127&amp;rft.aulast=Claesen&amp;rft.aufirst=Marc&amp;rft.au=Bart+De+Moor&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-bergstra-5"><span class="mw-cite-backlink">^ <a href="#cite_ref-bergstra_5-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-bergstra_5-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-bergstra_5-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFBergstraBengio2012" class="citation journal cs1">Bergstra, James; Bengio, Yoshua (2012). <a rel="nofollow" class="external text" href="http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf">"Random Search for Hyper-Parameter Optimization"</a> <span class="cs1-format">(PDF)</span>. <i>Journal of Machine Learning Research</i>. <b>13</b>: <span class="nowrap">281–</span>305.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Machine+Learning+Research&amp;rft.atitle=Random+Search+for+Hyper-Parameter+Optimization&amp;rft.volume=13&amp;rft.pages=281-305&amp;rft.date=2012&amp;rft.aulast=Bergstra&amp;rft.aufirst=James&amp;rft.au=Bengio%2C+Yoshua&amp;rft_id=http%3A%2F%2Fjmlr.csail.mit.edu%2Fpapers%2Fvolume13%2Fbergstra12a%2Fbergstra12a.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text">Chin-Wei Hsu, Chih-Chung Chang and Chih-Jen Lin (2010). <a rel="nofollow" class="external text" href="http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf">A practical guide to support vector classification</a>. Technical Report, <a href="/wiki/National_Taiwan_University" title="National Taiwan University">National Taiwan University</a>.</span>
</li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFChicco2017" class="citation journal cs1">Chicco D (December 2017). <a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5721660">"Ten quick tips for machine learning in computational biology"</a>. <i>BioData Mining</i>. <b>10</b> (35): 35. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1186%2Fs13040-017-0155-3">10.1186/s13040-017-0155-3</a></span>. <a href="/wiki/PMC_(identifier)" class="mw-redirect" title="PMC (identifier)">PMC</a>&nbsp;<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5721660">5721660</a></span>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/29234465">29234465</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=BioData+Mining&amp;rft.atitle=Ten+quick+tips+for+machine+learning+in+computational+biology&amp;rft.volume=10&amp;rft.issue=35&amp;rft.pages=35&amp;rft.date=2017-12&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC5721660%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F29234465&amp;rft_id=info%3Adoi%2F10.1186%2Fs13040-017-0155-3&amp;rft.aulast=Chicco&amp;rft.aufirst=D&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC5721660&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFZiyuFrankMasrourDavid2016" class="citation journal cs1">Ziyu, Wang; Frank, Hutter; Masrour, Zoghi; David, Matheson; Nando, de Feitas (2016). "Bayesian Optimization in a Billion Dimensions via Random Embeddings". <i>Journal of Artificial Intelligence Research</i>. <b>55</b>: <span class="nowrap">361–</span>387. <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1301.1942">1301.1942</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1613%2Fjair.4806">10.1613/jair.4806</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:279236">279236</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Artificial+Intelligence+Research&amp;rft.atitle=Bayesian+Optimization+in+a+Billion+Dimensions+via+Random+Embeddings&amp;rft.volume=55&amp;rft.pages=361-387&amp;rft.date=2016&amp;rft_id=info%3Aarxiv%2F1301.1942&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A279236%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1613%2Fjair.4806&amp;rft.aulast=Ziyu&amp;rft.aufirst=Wang&amp;rft.au=Frank%2C+Hutter&amp;rft.au=Masrour%2C+Zoghi&amp;rft.au=David%2C+Matheson&amp;rft.au=Nando%2C+de+Feitas&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-hutter-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-hutter_9-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFHutterHoosLeyton-Brown2011" class="citation cs2">Hutter, Frank; Hoos, Holger; Leyton-Brown, Kevin (2011), "Sequential Model-Based Optimization for General Algorithm Configuration", <a rel="nofollow" class="external text" href="http://www.cs.ubc.ca/labs/beta/Projects/SMAC/papers/11-LION5-SMAC.pdf"><i>Learning and Intelligent Optimization</i></a> <span class="cs1-format">(PDF)</span>, Lecture Notes in Computer Science, vol.&nbsp;6683, pp.&nbsp;<span class="nowrap">507–</span>523, <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&nbsp;<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.307.8813">10.1.1.307.8813</a></span>, <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-3-642-25566-3_40">10.1007/978-3-642-25566-3_40</a>, <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/978-3-642-25565-6" title="Special:BookSources/978-3-642-25565-6"><bdi>978-3-642-25565-6</bdi></a>, <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:6944647">6944647</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Sequential+Model-Based+Optimization+for+General+Algorithm+Configuration&amp;rft.btitle=Learning+and+Intelligent+Optimization&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.pages=507-523&amp;rft.date=2011&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.307.8813%23id-name%3DCiteSeerX&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A6944647%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-642-25566-3_40&amp;rft.isbn=978-3-642-25565-6&amp;rft.aulast=Hutter&amp;rft.aufirst=Frank&amp;rft.au=Hoos%2C+Holger&amp;rft.au=Leyton-Brown%2C+Kevin&amp;rft_id=http%3A%2F%2Fwww.cs.ubc.ca%2Flabs%2Fbeta%2FProjects%2FSMAC%2Fpapers%2F11-LION5-SMAC.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-bergstra11-10"><span class="mw-cite-backlink">^ <a href="#cite_ref-bergstra11_10-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-bergstra11_10-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-bergstra11_10-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFBergstraBardenetBengioKegl2011" class="citation cs2">Bergstra, James; Bardenet, Remi; Bengio, Yoshua; Kegl, Balazs (2011), <a rel="nofollow" class="external text" href="http://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf">"Algorithms for hyper-parameter optimization"</a> <span class="cs1-format">(PDF)</span>, <i>Advances in Neural Information Processing Systems</i></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Advances+in+Neural+Information+Processing+Systems&amp;rft.atitle=Algorithms+for+hyper-parameter+optimization&amp;rft.date=2011&amp;rft.aulast=Bergstra&amp;rft.aufirst=James&amp;rft.au=Bardenet%2C+Remi&amp;rft.au=Bengio%2C+Yoshua&amp;rft.au=Kegl%2C+Balazs&amp;rft_id=http%3A%2F%2Fpapers.nips.cc%2Fpaper%2F4443-algorithms-for-hyper-parameter-optimization.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-snoek-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-snoek_11-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFSnoekLarochelleAdams2012" class="citation journal cs1">Snoek, Jasper; Larochelle, Hugo; Adams, Ryan (2012). <a rel="nofollow" class="external text" href="http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf">"Practical Bayesian Optimization of Machine Learning Algorithms"</a> <span class="cs1-format">(PDF)</span>. <i>Advances in Neural Information Processing Systems</i>. <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1206.2944">1206.2944</a></span>. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2012arXiv1206.2944S">2012arXiv1206.2944S</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Advances+in+Neural+Information+Processing+Systems&amp;rft.atitle=Practical+Bayesian+Optimization+of+Machine+Learning+Algorithms&amp;rft.date=2012&amp;rft_id=info%3Aarxiv%2F1206.2944&amp;rft_id=info%3Abibcode%2F2012arXiv1206.2944S&amp;rft.aulast=Snoek&amp;rft.aufirst=Jasper&amp;rft.au=Larochelle%2C+Hugo&amp;rft.au=Adams%2C+Ryan&amp;rft_id=http%3A%2F%2Fpapers.nips.cc%2Fpaper%2F4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-thornton-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-thornton_12-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFThorntonHutterHoosLeyton-Brown2013" class="citation journal cs1">Thornton, Chris; Hutter, Frank; Hoos, Holger; Leyton-Brown, Kevin (2013). <a rel="nofollow" class="external text" href="http://www.cs.ubc.ca/labs/beta/Projects/autoweka/papers/autoweka.pdf">"Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms"</a> <span class="cs1-format">(PDF)</span>. <i>Knowledge Discovery and Data Mining</i>. <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1208.3719">1208.3719</a></span>. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2012arXiv1208.3719T">2012arXiv1208.3719T</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Knowledge+Discovery+and+Data+Mining&amp;rft.atitle=Auto-WEKA%3A+Combined+selection+and+hyperparameter+optimization+of+classification+algorithms&amp;rft.date=2013&amp;rft_id=info%3Aarxiv%2F1208.3719&amp;rft_id=info%3Abibcode%2F2012arXiv1208.3719T&amp;rft.aulast=Thornton&amp;rft.aufirst=Chris&amp;rft.au=Hutter%2C+Frank&amp;rft.au=Hoos%2C+Holger&amp;rft.au=Leyton-Brown%2C+Kevin&amp;rft_id=http%3A%2F%2Fwww.cs.ubc.ca%2Flabs%2Fbeta%2FProjects%2Fautoweka%2Fpapers%2Fautoweka.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-krnc-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-krnc_13-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKernc2024" class="citation cs2">Kernc (2024), <a rel="nofollow" class="external text" href="https://zenodo.org/records/14461363"><i>SAMBO: Sequential And Model-Based Optimization: Efficient global optimization in Python</i></a>, <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.5281%2Fzenodo.14461363">10.5281/zenodo.14461363</a><span class="reference-accessdate">, retrieved <span class="nowrap">2025-01-30</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=SAMBO%3A+Sequential+And+Model-Based+Optimization%3A+Efficient+global+optimization+in+Python&amp;rft.date=2024&amp;rft_id=info%3Adoi%2F10.5281%2Fzenodo.14461363&amp;rft.au=Kernc&amp;rft_id=https%3A%2F%2Fzenodo.org%2Frecords%2F14461363&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFLarsenHansenSvarerOhlsson1996" class="citation book cs1">Larsen, Jan; Hansen, Lars Kai; Svarer, Claus; Ohlsson, M (1996). <a rel="nofollow" class="external text" href="http://orbit.dtu.dk/files/4545571/Svarer.pdf">"Design and regularization of neural networks: The optimal use of a validation set"</a> <span class="cs1-format">(PDF)</span>. <i>Neural Networks for Signal Processing VI. Proceedings of the 1996 IEEE Signal Processing Society Workshop</i>. pp.&nbsp;<span class="nowrap">62–</span>71. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&nbsp;<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.415.3266">10.1.1.415.3266</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FNNSP.1996.548336">10.1109/NNSP.1996.548336</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="/wiki/Special:BookSources/0-7803-3550-3" title="Special:BookSources/0-7803-3550-3"><bdi>0-7803-3550-3</bdi></a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:238874">238874</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Design+and+regularization+of+neural+networks%3A+The+optimal+use+of+a+validation+set&amp;rft.btitle=Neural+Networks+for+Signal+Processing+VI.+Proceedings+of+the+1996+IEEE+Signal+Processing+Society+Workshop&amp;rft.pages=62-71&amp;rft.date=1996&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.415.3266%23id-name%3DCiteSeerX&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A238874%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FNNSP.1996.548336&amp;rft.isbn=0-7803-3550-3&amp;rft.aulast=Larsen&amp;rft.aufirst=Jan&amp;rft.au=Hansen%2C+Lars+Kai&amp;rft.au=Svarer%2C+Claus&amp;rft.au=Ohlsson%2C+M&amp;rft_id=http%3A%2F%2Forbit.dtu.dk%2Ffiles%2F4545571%2FSvarer.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFOlivier_ChapelleVladimir_VapnikOlivier_BousquetSayan_Mukherjee2002" class="citation journal cs1">Olivier Chapelle; Vladimir Vapnik; Olivier Bousquet; Sayan Mukherjee (2002). <a rel="nofollow" class="external text" href="http://www.chapelle.cc/olivier/pub/mlj02.pdf">"Choosing multiple parameters for support vector machines"</a> <span class="cs1-format">(PDF)</span>. <i>Machine Learning</i>. <b>46</b>: <span class="nowrap">131–</span>159. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1023%2Fa%3A1012450327387">10.1023/a:1012450327387</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=Choosing+multiple+parameters+for+support+vector+machines&amp;rft.volume=46&amp;rft.pages=131-159&amp;rft.date=2002&amp;rft_id=info%3Adoi%2F10.1023%2Fa%3A1012450327387&amp;rft.au=Olivier+Chapelle&amp;rft.au=Vladimir+Vapnik&amp;rft.au=Olivier+Bousquet&amp;rft.au=Sayan+Mukherjee&amp;rft_id=http%3A%2F%2Fwww.chapelle.cc%2Folivier%2Fpub%2Fmlj02.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFChuong_BChuan-Sheng_FooAndrew_Y_Ng2008" class="citation journal cs1">Chuong B; Chuan-Sheng Foo; Andrew Y Ng (2008). <a rel="nofollow" class="external text" href="http://papers.nips.cc/paper/3286-efficient-multiple-hyperparameter-learning-for-log-linear-models.pdf">"Efficient multiple hyperparameter learning for log-linear models"</a> <span class="cs1-format">(PDF)</span>. <i>Advances in Neural Information Processing Systems</i>. <b>20</b>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Advances+in+Neural+Information+Processing+Systems&amp;rft.atitle=Efficient+multiple+hyperparameter+learning+for+log-linear+models&amp;rft.volume=20&amp;rft.date=2008&amp;rft.au=Chuong+B&amp;rft.au=Chuan-Sheng+Foo&amp;rft.au=Andrew+Y+Ng&amp;rft_id=http%3A%2F%2Fpapers.nips.cc%2Fpaper%2F3286-efficient-multiple-hyperparameter-learning-for-log-linear-models.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFDomke2012" class="citation journal cs1">Domke, Justin (2012). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20140124182520/http://jmlr.org/proceedings/papers/v22/domke12/domke12.pdf">"Generic Methods for Optimization-Based Modeling"</a> <span class="cs1-format">(PDF)</span>. <i>Aistats</i>. <b>22</b>. Archived from <a rel="nofollow" class="external text" href="http://www.jmlr.org/proceedings/papers/v22/domke12/domke12.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 2014-01-24<span class="reference-accessdate">. Retrieved <span class="nowrap">2017-12-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Aistats&amp;rft.atitle=Generic+Methods+for+Optimization-Based+Modeling&amp;rft.volume=22&amp;rft.date=2012&amp;rft.aulast=Domke&amp;rft.aufirst=Justin&amp;rft_id=http%3A%2F%2Fwww.jmlr.org%2Fproceedings%2Fpapers%2Fv22%2Fdomke12%2Fdomke12.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-abs1502.03492-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-abs1502.03492_18-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFMaclaurinDuvenaudAdams2015" class="citation arxiv cs1">Maclaurin, Dougal; Duvenaud, David; Adams, Ryan P. (2015). "Gradient-based Hyperparameter Optimization through Reversible Learning". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1502.03492">1502.03492</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/stat.ML">stat.ML</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Gradient-based+Hyperparameter+Optimization+through+Reversible+Learning&amp;rft.date=2015&amp;rft_id=info%3Aarxiv%2F1502.03492&amp;rft.aulast=Maclaurin&amp;rft.aufirst=Dougal&amp;rft.au=Duvenaud%2C+David&amp;rft.au=Adams%2C+Ryan+P.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFFranceschiDoniniFrasconiPontil2017" class="citation journal cs1">Franceschi, Luca; Donini, Michele; Frasconi, Paolo; Pontil, Massimiliano (2017). <a rel="nofollow" class="external text" href="http://proceedings.mlr.press/v70/franceschi17a/franceschi17a-supp.pdf">"Forward and Reverse Gradient-Based Hyperparameter Optimization"</a> <span class="cs1-format">(PDF)</span>. <i>Proceedings of the 34th International Conference on Machine Learning</i>. <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1703.01785">1703.01785</a></span>. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2017arXiv170301785F">2017arXiv170301785F</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+34th+International+Conference+on+Machine+Learning&amp;rft.atitle=Forward+and+Reverse+Gradient-Based+Hyperparameter+Optimization&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1703.01785&amp;rft_id=info%3Abibcode%2F2017arXiv170301785F&amp;rft.aulast=Franceschi&amp;rft.aufirst=Luca&amp;rft.au=Donini%2C+Michele&amp;rft.au=Frasconi%2C+Paolo&amp;rft.au=Pontil%2C+Massimiliano&amp;rft_id=http%3A%2F%2Fproceedings.mlr.press%2Fv70%2Ffranceschi17a%2Ffranceschi17a-supp.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-20">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFShabanChengHatchBoots2018" class="citation arxiv cs1">Shaban, Amirreza; Cheng, Ching-An; Hatch, Nathan; Boots, Byron (2018). "Truncated Back-propagation for Bilevel Optimization". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1810.10667">1810.10667</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Truncated+Back-propagation+for+Bilevel+Optimization&amp;rft.date=2018&amp;rft_id=info%3Aarxiv%2F1810.10667&amp;rft.aulast=Shaban&amp;rft.aufirst=Amirreza&amp;rft.au=Cheng%2C+Ching-An&amp;rft.au=Hatch%2C+Nathan&amp;rft.au=Boots%2C+Byron&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-21">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFLorraineVicolDuvenaud2019" class="citation arxiv cs1">Lorraine, Jonathan; Vicol, Paul; Duvenaud, David (2019). "Optimizing Millions of Hyperparameters by Implicit Differentiation". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1911.02590">1911.02590</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Optimizing+Millions+of+Hyperparameters+by+Implicit+Differentiation&amp;rft.date=2019&amp;rft_id=info%3Aarxiv%2F1911.02590&amp;rft.aulast=Lorraine&amp;rft.aufirst=Jonathan&amp;rft.au=Vicol%2C+Paul&amp;rft.au=Duvenaud%2C+David&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-22">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFLorraineDuvenaud2018" class="citation arxiv cs1">Lorraine, Jonathan; Duvenaud, David (2018). "Stochastic Hyperparameter Optimization through Hypernetworks". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1802.09419">1802.09419</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Stochastic+Hyperparameter+Optimization+through+Hypernetworks&amp;rft.date=2018&amp;rft_id=info%3Aarxiv%2F1802.09419&amp;rft.aulast=Lorraine&amp;rft.aufirst=Jonathan&amp;rft.au=Duvenaud%2C+David&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-23">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFMacKayVicolLorraineDuvenaud2019" class="citation arxiv cs1">MacKay, Matthew; Vicol, Paul; Lorraine, Jon; Duvenaud, David; Grosse, Roger (2019). "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1903.03088">1903.03088</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Self-Tuning+Networks%3A+Bilevel+Optimization+of+Hyperparameters+using+Structured+Best-Response+Functions&amp;rft.date=2019&amp;rft_id=info%3Aarxiv%2F1903.03088&amp;rft.aulast=MacKay&amp;rft.aufirst=Matthew&amp;rft.au=Vicol%2C+Paul&amp;rft.au=Lorraine%2C+Jon&amp;rft.au=Duvenaud%2C+David&amp;rft.au=Grosse%2C+Roger&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-24">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFBaeGrosse2020" class="citation arxiv cs1">Bae, Juhan; Grosse, Roger (2020). "Delta-STN: Efficient Bilevel Optimization for Neural Networks using Structured Response Jacobians". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2010.13514">2010.13514</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Delta-STN%3A+Efficient+Bilevel+Optimization+for+Neural+Networks+using+Structured+Response+Jacobians&amp;rft.date=2020&amp;rft_id=info%3Aarxiv%2F2010.13514&amp;rft.aulast=Bae&amp;rft.aufirst=Juhan&amp;rft.au=Grosse%2C+Roger&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFLiuSimonyanYang2018" class="citation arxiv cs1">Liu, Hanxiao; Simonyan, Karen; Yang, Yiming (2018). "DARTS: Differentiable Architecture Search". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1806.09055">1806.09055</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=DARTS%3A+Differentiable+Architecture+Search&amp;rft.date=2018&amp;rft_id=info%3Aarxiv%2F1806.09055&amp;rft.aulast=Liu&amp;rft.aufirst=Hanxiao&amp;rft.au=Simonyan%2C+Karen&amp;rft.au=Yang%2C+Yiming&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-kousiouris1-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-kousiouris1_26-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKousiourisCuccinottaVarvarigou2011" class="citation journal cs1">Kousiouris G, Cuccinotta T, Varvarigou T (2011). <a rel="nofollow" class="external text" href="https://www.sciencedirect.com/science/article/abs/pii/S0164121211000951">"The effects of scheduling, workload type and consolidation scenarios on virtual machine performance and their prediction through optimized artificial neural networks"</a>. <i>Journal of Systems and Software</i>. <b>84</b> (8): <span class="nowrap">1270–</span>1291. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.jss.2011.04.013">10.1016/j.jss.2011.04.013</a>. <a href="/wiki/Hdl_(identifier)" class="mw-redirect" title="Hdl (identifier)">hdl</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://hdl.handle.net/11382%2F361472">11382/361472</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Systems+and+Software&amp;rft.atitle=The+effects+of+scheduling%2C+workload+type+and+consolidation+scenarios+on+virtual+machine+performance+and+their+prediction+through+optimized+artificial+neural+networks&amp;rft.volume=84&amp;rft.issue=8&amp;rft.pages=1270-1291&amp;rft.date=2011&amp;rft_id=info%3Ahdl%2F11382%2F361472&amp;rft_id=info%3Adoi%2F10.1016%2Fj.jss.2011.04.013&amp;rft.aulast=Kousiouris&amp;rft.aufirst=G&amp;rft.au=Cuccinotta%2C+T&amp;rft.au=Varvarigou%2C+T&amp;rft_id=https%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fabs%2Fpii%2FS0164121211000951&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-miikkulainen1-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-miikkulainen1_27-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFMiikkulainenLiangMeyersonRawal2017" class="citation arxiv cs1">Miikkulainen R, Liang J, Meyerson E, Rawal A, Fink D, Francon O, Raju B, Shahrzad H, Navruzyan A, Duffy N, Hodjat B (2017). "Evolving Deep Neural Networks". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1703.00548">1703.00548</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.NE">cs.NE</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Evolving+Deep+Neural+Networks&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1703.00548&amp;rft.aulast=Miikkulainen&amp;rft.aufirst=R&amp;rft.au=Liang%2C+J&amp;rft.au=Meyerson%2C+E&amp;rft.au=Rawal%2C+A&amp;rft.au=Fink%2C+D&amp;rft.au=Francon%2C+O&amp;rft.au=Raju%2C+B&amp;rft.au=Shahrzad%2C+H&amp;rft.au=Navruzyan%2C+A&amp;rft.au=Duffy%2C+N&amp;rft.au=Hodjat%2C+B&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-jaderberg1-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-jaderberg1_28-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFJaderbergDalibardOsinderoCzarnecki2017" class="citation arxiv cs1">Jaderberg M, Dalibard V, Osindero S, Czarnecki WM, Donahue J, Razavi A, Vinyals O, Green T, Dunning I, Simonyan K, Fernando C, Kavukcuoglu K (2017). "Population Based Training of Neural Networks". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1711.09846">1711.09846</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Population+Based+Training+of+Neural+Networks&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1711.09846&amp;rft.aulast=Jaderberg&amp;rft.aufirst=M&amp;rft.au=Dalibard%2C+V&amp;rft.au=Osindero%2C+S&amp;rft.au=Czarnecki%2C+WM&amp;rft.au=Donahue%2C+J&amp;rft.au=Razavi%2C+A&amp;rft.au=Vinyals%2C+O&amp;rft.au=Green%2C+T&amp;rft.au=Dunning%2C+I&amp;rft.au=Simonyan%2C+K&amp;rft.au=Fernando%2C+C&amp;rft.au=Kavukcuoglu%2C+K&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-such1-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-such1_29-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFSuchMadhavanContiLehman2017" class="citation arxiv cs1">Such FP, Madhavan V, Conti E, Lehman J, Stanley KO, Clune J (2017). "Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1712.06567">1712.06567</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.NE">cs.NE</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Deep+Neuroevolution%3A+Genetic+Algorithms+Are+a+Competitive+Alternative+for+Training+Deep+Neural+Networks+for+Reinforcement+Learning&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1712.06567&amp;rft.aulast=Such&amp;rft.aufirst=FP&amp;rft.au=Madhavan%2C+V&amp;rft.au=Conti%2C+E&amp;rft.au=Lehman%2C+J&amp;rft.au=Stanley%2C+KO&amp;rft.au=Clune%2C+J&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-30">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFLiSpyraPerelDalibard2019" class="citation arxiv cs1">Li, Ang; Spyra, Ola; Perel, Sagi; Dalibard, Valentin; Jaderberg, Max; Gu, Chenjie; Budden, David; Harley, Tim; Gupta, Pramod (2019-02-05). "A Generalized Framework for Population Based Training". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1902.01894">1902.01894</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.AI">cs.AI</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=A+Generalized+Framework+for+Population+Based+Training&amp;rft.date=2019-02-05&amp;rft_id=info%3Aarxiv%2F1902.01894&amp;rft.aulast=Li&amp;rft.aufirst=Ang&amp;rft.au=Spyra%2C+Ola&amp;rft.au=Perel%2C+Sagi&amp;rft.au=Dalibard%2C+Valentin&amp;rft.au=Jaderberg%2C+Max&amp;rft.au=Gu%2C+Chenjie&amp;rft.au=Budden%2C+David&amp;rft.au=Harley%2C+Tim&amp;rft.au=Gupta%2C+Pramod&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-irace-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-irace_31-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFLópez-IbáñezDubois-LacostePérez_CáceresStützle2016" class="citation journal cs1">López-Ibáñez, Manuel; Dubois-Lacoste, Jérémie; Pérez Cáceres, Leslie; Stützle, Thomas; Birattari, Mauro (2016). <a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.orp.2016.09.002">"The irace package: Iterated Racing for Automatic Algorithm Configuration"</a>. <i>Operations Research Perspective</i>. <b>3</b> (3): <span class="nowrap">43–</span>58. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.orp.2016.09.002">10.1016/j.orp.2016.09.002</a></span>. <a href="/wiki/Hdl_(identifier)" class="mw-redirect" title="Hdl (identifier)">hdl</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://hdl.handle.net/10419%2F178265">10419/178265</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Operations+Research+Perspective&amp;rft.atitle=The+irace+package%3A+Iterated+Racing+for+Automatic+Algorithm+Configuration&amp;rft.volume=3&amp;rft.issue=3&amp;rft.pages=43-58&amp;rft.date=2016&amp;rft_id=info%3Ahdl%2F10419%2F178265&amp;rft_id=info%3Adoi%2F10.1016%2Fj.orp.2016.09.002&amp;rft.aulast=L%C3%B3pez-Ib%C3%A1%C3%B1ez&amp;rft.aufirst=Manuel&amp;rft.au=Dubois-Lacoste%2C+J%C3%A9r%C3%A9mie&amp;rft.au=P%C3%A9rez+C%C3%A1ceres%2C+Leslie&amp;rft.au=St%C3%BCtzle%2C+Thomas&amp;rft.au=Birattari%2C+Mauro&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1016%252Fj.orp.2016.09.002&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-race-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-race_32-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFBirattariStützlePaqueteVarrentrapp2002" class="citation journal cs1">Birattari, Mauro; Stützle, Thomas; Paquete, Luis; Varrentrapp, Klaus (2002). "A Racing Algorithm for Configuring Metaheuristics". <i>Gecco 2002</i>: <span class="nowrap">11–</span>18.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Gecco+2002&amp;rft.atitle=A+Racing+Algorithm+for+Configuring+Metaheuristics&amp;rft.pages=11-18&amp;rft.date=2002&amp;rft.aulast=Birattari&amp;rft.aufirst=Mauro&amp;rft.au=St%C3%BCtzle%2C+Thomas&amp;rft.au=Paquete%2C+Luis&amp;rft.au=Varrentrapp%2C+Klaus&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-33">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFJamiesonTalwalkar2015" class="citation arxiv cs1">Jamieson, Kevin; Talwalkar, Ameet (2015-02-27). "Non-stochastic Best Arm Identification and Hyperparameter Optimization". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1502.07943">1502.07943</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Non-stochastic+Best+Arm+Identification+and+Hyperparameter+Optimization&amp;rft.date=2015-02-27&amp;rft_id=info%3Aarxiv%2F1502.07943&amp;rft.aulast=Jamieson&amp;rft.aufirst=Kevin&amp;rft.au=Talwalkar%2C+Ameet&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-34">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFLiJamiesonRostamizadehGonina2020" class="citation arxiv cs1">Li, Liam; Jamieson, Kevin; Rostamizadeh, Afshin; Gonina, Ekaterina; Hardt, Moritz; Recht, Benjamin; Talwalkar, Ameet (2020-03-16). "A System for Massively Parallel Hyperparameter Tuning". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1810.05934v5">1810.05934v5</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=A+System+for+Massively+Parallel+Hyperparameter+Tuning&amp;rft.date=2020-03-16&amp;rft_id=info%3Aarxiv%2F1810.05934v5&amp;rft.aulast=Li&amp;rft.aufirst=Liam&amp;rft.au=Jamieson%2C+Kevin&amp;rft.au=Rostamizadeh%2C+Afshin&amp;rft.au=Gonina%2C+Ekaterina&amp;rft.au=Hardt%2C+Moritz&amp;rft.au=Recht%2C+Benjamin&amp;rft.au=Talwalkar%2C+Ameet&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-35"><span class="mw-cite-backlink"><b><a href="#cite_ref-35">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFLiJamiesonDeSalvoRostamizadeh2020" class="citation journal cs1">Li, Lisha; Jamieson, Kevin; DeSalvo, Giulia; Rostamizadeh, Afshin; Talwalkar, Ameet (2020-03-16). "Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization". <i>Journal of Machine Learning Research</i>. <b>18</b>: <span class="nowrap">1–</span>52. <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1603.06560">1603.06560</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Machine+Learning+Research&amp;rft.atitle=Hyperband%3A+A+Novel+Bandit-Based+Approach+to+Hyperparameter+Optimization&amp;rft.volume=18&amp;rft.pages=1-52&amp;rft.date=2020-03-16&amp;rft_id=info%3Aarxiv%2F1603.06560&amp;rft.aulast=Li&amp;rft.aufirst=Lisha&amp;rft.au=Jamieson%2C+Kevin&amp;rft.au=DeSalvo%2C+Giulia&amp;rft.au=Rostamizadeh%2C+Afshin&amp;rft.au=Talwalkar%2C+Ameet&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-abs1705.08520-36"><span class="mw-cite-backlink"><b><a href="#cite_ref-abs1705.08520_36-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFDiazFokoueNanniciniSamulowitz2017" class="citation arxiv cs1">Diaz, Gonzalo; Fokoue, Achille; Nannicini, Giacomo; Samulowitz, Horst (2017). "An effective algorithm for hyperparameter optimization of neural networks". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1705.08520">1705.08520</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.AI">cs.AI</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=An+effective+algorithm+for+hyperparameter+optimization+of+neural+networks&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1705.08520&amp;rft.aulast=Diaz&amp;rft.aufirst=Gonzalo&amp;rft.au=Fokoue%2C+Achille&amp;rft.au=Nannicini%2C+Giacomo&amp;rft.au=Samulowitz%2C+Horst&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
<li id="cite_note-abs1706.00764-37"><span class="mw-cite-backlink"><b><a href="#cite_ref-abs1706.00764_37-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFHazanKlivansYuan2017" class="citation arxiv cs1">Hazan, Elad; Klivans, Adam; Yuan, Yang (2017). "Hyperparameter Optimization: A Spectral Approach". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1706.00764">1706.00764</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Hyperparameter+Optimization%3A+A+Spectral+Approach&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1706.00764&amp;rft.aulast=Hazan&amp;rft.aufirst=Elad&amp;rft.au=Klivans%2C+Adam&amp;rft.au=Yuan%2C+Yang&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHyperparameter+optimization" class="Z3988"></span></span>
</li>
</ol></div>
<div class="navbox-styles"><style data-mw-deduplicate="TemplateStyles:r1129693374">.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:": "}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:" · ";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:" (";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:")";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:" "counter(listitem)"\a0 "}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:" ("counter(listitem)"\a0 "}</style><style data-mw-deduplicate="TemplateStyles:r1236075235">.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}</style></div><div role="navigation" class="navbox" aria-labelledby="Differentiable_computing254" style="padding:3px"><table class="nowraplinks hlist mw-collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1129693374"><style data-mw-deduplicate="TemplateStyles:r1239400231">.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}</style><div class="navbar plainlinks hlist navbar-mini"><ul><li class="nv-view"><a href="/wiki/Template:Differentiable_computing" title="Template:Differentiable computing"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Differentiable_computing" title="Template talk:Differentiable computing"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a href="/wiki/Special:EditPage/Template:Differentiable_computing" title="Special:EditPage/Template:Differentiable computing"><abbr title="Edit this template">e</abbr></a></li></ul></div><div id="Differentiable_computing254" style="font-size:114%;margin:0 4em">Differentiable computing</div></th></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Differentiable_function" title="Differentiable function">General</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><b><a href="/wiki/Differentiable_programming" title="Differentiable programming">Differentiable programming</a></b></li>
<li><a href="/wiki/Information_geometry" title="Information geometry">Information geometry</a></li>
<li><a href="/wiki/Statistical_manifold" title="Statistical manifold">Statistical manifold</a></li>
<li><a href="/wiki/Automatic_differentiation" title="Automatic differentiation">Automatic differentiation</a></li>
<li><a href="/wiki/Neuromorphic_computing" title="Neuromorphic computing">Neuromorphic computing</a></li>
<li><a href="/wiki/Pattern_recognition" title="Pattern recognition">Pattern recognition</a></li>
<li><a href="/wiki/Ricci_calculus" title="Ricci calculus">Ricci calculus</a></li>
<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>
<li><a href="/wiki/Inductive_bias" title="Inductive bias">Inductive bias</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Hardware</th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Graphcore" title="Graphcore">IPU</a></li>
<li><a href="/wiki/Tensor_Processing_Unit" title="Tensor Processing Unit">TPU</a></li>
<li><a href="/wiki/Vision_processing_unit" title="Vision processing unit">VPU</a></li>
<li><a href="/wiki/Memristor" title="Memristor">Memristor</a></li>
<li><a href="/wiki/SpiNNaker" title="SpiNNaker">SpiNNaker</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Software libraries</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/TensorFlow" title="TensorFlow">TensorFlow</a></li>
<li><a href="/wiki/PyTorch" title="PyTorch">PyTorch</a></li>
<li><a href="/wiki/Keras" title="Keras">Keras</a></li>
<li><a href="/wiki/Scikit-learn" title="Scikit-learn">scikit-learn</a></li>
<li><a href="/wiki/Theano_(software)" title="Theano (software)">Theano</a></li>
<li><a href="/wiki/JAX_(software)" title="JAX (software)">JAX</a></li>
<li><a href="/wiki/Flux_(machine-learning_framework)" title="Flux (machine-learning framework)">Flux.jl</a></li>
<li><a href="/wiki/MindSpore" title="MindSpore">MindSpore</a></li></ul>
</div></td></tr><tr><td class="navbox-abovebelow" colspan="2"><div>
<ul><li><span class="noviewer" typeof="mw:File"><a href="/wiki/File:Symbol_portal_class.svg" class="mw-file-description" title="Portal"><img alt="" src="//upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/20px-Symbol_portal_class.svg.png" decoding="async" width="16" height="16" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/40px-Symbol_portal_class.svg.png 1.5x" data-file-width="180" data-file-height="185"></a></span> Portals
<ul><li><a href="/wiki/Portal:Computer_programming" title="Portal:Computer programming">Computer programming</a></li>
<li><a href="/wiki/Portal:Technology" title="Portal:Technology">Technology</a></li></ul></li></ul>
</div></td></tr></tbody></table></div>
<!-- 
NewPP limit report
Parsed by mw‐web.eqiad.main‐5f99d748c‐psmq4
Cached time: 20250728182358
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.729 seconds
Real time usage: 0.876 seconds
Preprocessor visited node count: 2636/1000000
Revision size: 24864/2097152 bytes
Post‐expand include size: 100036/2097152 bytes
Template argument size: 2939/2097152 bytes
Highest expansion depth: 11/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 142940/5000000 bytes
Lua time usage: 0.518/10.000 seconds
Lua memory usage: 5491509/52428800 bytes
Number of Wikibase entities loaded: 0/500
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  747.376      1 -total
 64.92%  485.186      1 Template:Reflist
 31.95%  238.753     14 Template:Cite_journal
 21.48%  160.534     17 Template:Cite_arXiv
 15.39%  115.031      1 Template:Differentiable_computing
 15.15%  113.205      1 Template:Navbox
 12.59%   94.105      1 Template:Short_description
  6.63%   49.576      2 Template:Pagetype
  4.16%   31.072      2 Template:Main
  4.04%   30.203      3 Template:Main_other
-->

<!-- Saved in parser cache with key enwiki:pcache:54361643:|#|:idhash:canonical and timestamp 20250728182358 and revision id 1299851399. Rendering was triggered because: page-view
 -->
</div><!--esi <esi:include src="/esitest-fa8a495983347898/content" /> --><noscript><img src="https://en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1&amp;usesul3=1" alt="" width="1" height="1" style="border: none; position: absolute;"></noscript>
<div class="printfooter" data-nosnippet="">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Hyperparameter_optimization&amp;oldid=1299851399#Grid_search">https://en.wikipedia.org/w/index.php?title=Hyperparameter_optimization&amp;oldid=1299851399#Grid_search</a>"</div></div>
					<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Machine_learning" title="Category:Machine learning">Machine learning</a></li><li><a href="/wiki/Category:Mathematical_optimization" title="Category:Mathematical optimization">Mathematical optimization</a></li><li><a href="/wiki/Category:Model_selection" title="Category:Model selection">Model selection</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:Articles_with_short_description" title="Category:Articles with short description">Articles with short description</a></li><li><a href="/wiki/Category:Short_description_is_different_from_Wikidata" title="Category:Short description is different from Wikidata">Short description is different from Wikidata</a></li></ul></div></div>
				</div>
			</main>
			
		</div>
		<div class="mw-footer-container">
			
<footer id="footer" class="mw-footer" >
	<ul id="footer-info">
	<li id="footer-info-lastmod"> This page was last edited on 10 July 2025, at 20:12<span class="anonymous-show">&#160;(UTC)</span>.</li>
	<li id="footer-info-copyright">Text is available under the <a href="/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License" title="Wikipedia:Text of the Creative Commons Attribution-ShareAlike 4.0 International License">Creative Commons Attribution-ShareAlike 4.0 License</a>;
additional terms may apply. By using this site, you agree to the <a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use" class="extiw" title="foundation:Special:MyLanguage/Policy:Terms of Use">Terms of Use</a> and <a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy" class="extiw" title="foundation:Special:MyLanguage/Policy:Privacy policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a rel="nofollow" class="external text" href="https://wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
</ul>

	<ul id="footer-places">
	<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy">Privacy policy</a></li>
	<li id="footer-places-about"><a href="/wiki/Wikipedia:About">About Wikipedia</a></li>
	<li id="footer-places-disclaimers"><a href="/wiki/Wikipedia:General_disclaimer">Disclaimers</a></li>
	<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
	<li id="footer-places-wm-codeofconduct"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct">Code of Conduct</a></li>
	<li id="footer-places-developers"><a href="https://developer.wikimedia.org">Developers</a></li>
	<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
	<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement">Cookie statement</a></li>
	<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Hyperparameter_optimization&amp;mobileaction=toggle_view_mobile#Grid_search" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
</ul>

	<ul id="footer-icons" class="noprint">
	<li id="footer-copyrightico"><a href="https://www.wikimedia.org/" class="cdx-button cdx-button--fake-button cdx-button--size-large cdx-button--fake-button--enabled"><picture><source media="(min-width: 500px)" srcset="/static/images/footer/wikimedia-button.svg" width="84" height="29"><img src="/static/images/footer/wikimedia.svg" width="25" height="25" alt="Wikimedia Foundation" lang="en" loading="lazy"></picture></a></li>
	<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/" class="cdx-button cdx-button--fake-button cdx-button--size-large cdx-button--fake-button--enabled"><picture><source media="(min-width: 500px)" srcset="/w/resources/assets/poweredby_mediawiki.svg" width="88" height="31"><img src="/w/resources/assets/mediawiki_compact.svg" alt="Powered by MediaWiki" lang="en" width="25" height="25" loading="lazy"></picture></a></li>
</ul>

</footer>

		</div>
	</div> 
</div> 
<div class="vector-header-container vector-sticky-header-container no-font-mode-scale">
	<div id="vector-sticky-header" class="vector-sticky-header">
		<div class="vector-sticky-header-start">
			<div class="vector-sticky-header-icon-start vector-button-flush-left vector-button-flush-right" aria-hidden="true">
				<button class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-sticky-header-search-toggle" tabindex="-1" data-event-name="ui.vector-sticky-search-form.icon"><span class="vector-icon mw-ui-icon-search mw-ui-icon-wikimedia-search"></span>

<span>Search</span>
			</button>
		</div>
			
		<div role="search" class="vector-search-box-vue  vector-search-box-show-thumbnail vector-search-box">
			<div class="vector-typeahead-search-container">
				<div class="cdx-typeahead-search cdx-typeahead-search--show-thumbnail">
					<form action="/w/index.php" id="vector-sticky-search-form" class="cdx-search-input cdx-search-input--has-end-button">
						<div  class="cdx-search-input__input-wrapper"  data-search-loc="header-moved">
							<div class="cdx-text-input cdx-text-input--has-start-icon">
								<input
									class="cdx-text-input__input mw-searchInput" autocomplete="off"
									
									type="search" name="search" placeholder="Search Wikipedia">
								<span class="cdx-text-input__icon cdx-text-input__start-icon"></span>
							</div>
							<input type="hidden" name="title" value="Special:Search">
						</div>
						<button class="cdx-button cdx-search-input__end-button">Search</button>
					</form>
				</div>
			</div>
		</div>
		<div class="vector-sticky-header-context-bar">
				<nav aria-label="Contents" class="vector-toc-landmark">
						
					<div id="vector-sticky-header-toc" class="vector-dropdown mw-portlet mw-portlet-sticky-header-toc vector-sticky-header-toc vector-button-flush-left"  >
						<input type="checkbox" id="vector-sticky-header-toc-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-sticky-header-toc" class="vector-dropdown-checkbox "  aria-label="Toggle the table of contents"  >
						<label id="vector-sticky-header-toc-label" for="vector-sticky-header-toc-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-listBullet mw-ui-icon-wikimedia-listBullet"></span>

<span class="vector-dropdown-label-text">Toggle the table of contents</span>
						</label>
						<div class="vector-dropdown-content">
					
						<div id="vector-sticky-header-toc-unpinned-container" class="vector-unpinned-container">
						</div>
					
						</div>
					</div>
			</nav>
				<div class="vector-sticky-header-context-bar-primary" aria-hidden="true" ><span class="mw-page-title-main">Hyperparameter optimization</span></div>
			</div>
		</div>
		<div class="vector-sticky-header-end" aria-hidden="true">
			<div class="vector-sticky-header-icons">
				<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only" id="ca-talk-sticky-header" tabindex="-1" data-event-name="talk-sticky-header"><span class="vector-icon mw-ui-icon-speechBubbles mw-ui-icon-wikimedia-speechBubbles"></span>

<span></span>
			</a>
			<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only" id="ca-subject-sticky-header" tabindex="-1" data-event-name="subject-sticky-header"><span class="vector-icon mw-ui-icon-article mw-ui-icon-wikimedia-article"></span>

<span></span>
			</a>
			<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only" id="ca-history-sticky-header" tabindex="-1" data-event-name="history-sticky-header"><span class="vector-icon mw-ui-icon-wikimedia-history mw-ui-icon-wikimedia-wikimedia-history"></span>

<span></span>
			</a>
			<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only mw-watchlink" id="ca-watchstar-sticky-header" tabindex="-1" data-event-name="watch-sticky-header"><span class="vector-icon mw-ui-icon-wikimedia-star mw-ui-icon-wikimedia-wikimedia-star"></span>

<span></span>
			</a>
			<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only" id="ca-edit-sticky-header" tabindex="-1" data-event-name="wikitext-edit-sticky-header"><span class="vector-icon mw-ui-icon-wikimedia-wikiText mw-ui-icon-wikimedia-wikimedia-wikiText"></span>

<span></span>
			</a>
			<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only" id="ca-ve-edit-sticky-header" tabindex="-1" data-event-name="ve-edit-sticky-header"><span class="vector-icon mw-ui-icon-wikimedia-edit mw-ui-icon-wikimedia-wikimedia-edit"></span>

<span></span>
			</a>
			<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only" id="ca-viewsource-sticky-header" tabindex="-1" data-event-name="ve-edit-protected-sticky-header"><span class="vector-icon mw-ui-icon-wikimedia-editLock mw-ui-icon-wikimedia-wikimedia-editLock"></span>

<span></span>
			</a>
		</div>
			<div class="vector-sticky-header-buttons">
				<button class="cdx-button cdx-button--weight-quiet mw-interlanguage-selector" id="p-lang-btn-sticky-header" tabindex="-1" data-event-name="ui.dropdown-p-lang-btn-sticky-header"><span class="vector-icon mw-ui-icon-wikimedia-language mw-ui-icon-wikimedia-wikimedia-language"></span>

<span>10 languages</span>
			</button>
			<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--action-progressive" id="ca-addsection-sticky-header" tabindex="-1" data-event-name="addsection-sticky-header"><span class="vector-icon mw-ui-icon-speechBubbleAdd-progressive mw-ui-icon-wikimedia-speechBubbleAdd-progressive"></span>

<span>Add topic</span>
			</a>
		</div>
			<div class="vector-sticky-header-icon-end">
				<div class="vector-user-links">
				</div>
			</div>
		</div>
	</div>
</div>
<div class="mw-portlet mw-portlet-dock-bottom emptyPortlet" id="p-dock-bottom">
	<ul>
		
	</ul>
</div>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgHostname":"mw-web.eqiad.main-7db977f6b8-pdc4b","wgBackendResponseTime":166,"wgPageParseReport":{"limitreport":{"cputime":"0.729","walltime":"0.876","ppvisitednodes":{"value":2636,"limit":1000000},"revisionsize":{"value":24864,"limit":2097152},"postexpandincludesize":{"value":100036,"limit":2097152},"templateargumentsize":{"value":2939,"limit":2097152},"expansiondepth":{"value":11,"limit":100},"expensivefunctioncount":{"value":3,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":142940,"limit":5000000},"entityaccesscount":{"value":0,"limit":500},"timingprofile":["100.00%  747.376      1 -total"," 64.92%  485.186      1 Template:Reflist"," 31.95%  238.753     14 Template:Cite_journal"," 21.48%  160.534     17 Template:Cite_arXiv"," 15.39%  115.031      1 Template:Differentiable_computing"," 15.15%  113.205      1 Template:Navbox"," 12.59%   94.105      1 Template:Short_description","  6.63%   49.576      2 Template:Pagetype","  4.16%   31.072      2 Template:Main","  4.04%   30.203      3 Template:Main_other"]},"scribunto":{"limitreport-timeusage":{"value":"0.518","limit":"10.000"},"limitreport-memusage":{"value":5491509,"limit":52428800}},"cachereport":{"origin":"mw-web.eqiad.main-5f99d748c-psmq4","timestamp":"20250728182358","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Hyperparameter optimization","url":"https:\/\/en.wikipedia.org\/wiki\/Hyperparameter_optimization#Grid_search","sameAs":"http:\/\/www.wikidata.org\/entity\/Q48996162","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q48996162","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2017-06-22T00:09:19Z","dateModified":"2025-07-10T20:12:33Z","headline":"choosing a set of optimal hyperparameters for a learning algorithm"}</script>
</body>
</html>